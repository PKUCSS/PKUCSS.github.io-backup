<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Chinese Probing Dataset 中文探测任务数据集]]></title>
    <url>%2F2019%2F12%2F22%2FChinese-Probing-Dataset-%E4%B8%AD%E6%96%87%E6%8E%A2%E6%B5%8B%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Chinese-Probing-Dataset中文探测任务数据集，可用于Deep NLP可解释性工作，详见https://github.com/PKUCSS/Chinese-Probing-Dataset 。 Probing Task dataset built from Chinese Wiki Corpus for NLP interpretability work Probing TaskThe idea of probing tasks are desctibed in the paper “What you can cram into a single vector: Probing sentence embeddings for linguistic properties“.They are meant to analyse what linguistic information can be extracted from sentence embeddings.Since it was proposed, it has been widely used to explain the learning mechanism of English Corpus,e.g,the ACL 2019 paper What does Bert Learn about the Structure of Language. Chinese DatasetHowever,the corresponding Chinese dataset is still waiting to be built,wihch is a obstacle in the field of deep NLP interpretability work on Chinese.To solve it,I built the dataset from ChineseWiki Corpus provided by Chinse Glue Project.The task setting is adapted from the original English version provided by Sent Eval.The details are given below. Task SettingAll data sets contain ~100k training instances, ~10k validation instances and ~10k test instances, and in all cases they are balanced across the target classes (in some cases, there are a few more instances, as a result of balancing constraints in the sampling process). Each instance is on a separate line, and contains (at least) the following tab-separated fields: the first field specifies the partition (tr/va/te); the second field specifies the ground-truth class of the instance (e.g., O(Original)/I(Inverted) in the bshift.txt file); the last field contains the sentence which has been word segmentated. Surface Taskssent_len.txt This is a classification task where the goal is to predict the sentence length which has been binned in 6 possible categories with lengths ranging in the following intervals: 0: (5-10), 1: (11-15), 2: (15-20), 3: (21-30), 4: (31-40), 5: (41-50).The length is measured by the number of Chinse words,and the word segmentation is done by python-stanford-corenlp. sent_len_by_char.txt This is a classification task where the goal is to predict the sentence length which has been binned in 6 possible categories with lengths ranging in the following intervals: 0: (5-10), 1: (11-15), 2: (15-20), 3: (21-30), 4: (31-40), 5: (41-50).The length is measured by the number of Chinse characters. wc.txt(word content) This is a classification task with 1000 words as targets. The task is predicting which of the target words appear on the given sentence. We constructed the data by picking 1000 mid-frequecny pure Chinese words occurring in the corpus vocabulary.Each sentence contains a single target word, and the word occurs exactly once in the sentence. cc.txt(char content) This is a classification task with 1000 Chinese characters as targets. The task is predicting which of the target characters appear on the given sentence. We constructed the data by picking 1000 mid-frequecny Chinese charactres occurring in the corpus vocabulary.Each sentence contains a single target character, and the character occurs exactly once in the sentence. Syntatic Taskstree_depth.txt This is a classification tasks where the goal is to predict the maximum depth of the sentence’s syntactic tree (with values ranging from 5 to 11).The syntactic tree are generated by python-stanford-corenlp. bshift.txt(bigram shift) In this classification task the goal is to predict whether two consecutive tokens within the sentence have been inverted (label I for inversion and O for original). The data was constructed by choosing two random consecutive Chinese word in the sentence, excluding beginning of sentence and punctuation marks. We also excluded sentences containing double quotes. cbshift.txt(char bigram shift) In this classification task the goal is to predict whether two consecutive tokens within the sentence have been inverted (label I for inversion and O for original). The data was constructed by choosing two random consecutive Chinse characters in the sentence, excluding beginning of sentence and punctuation marks. We also excluded sentences containing double quotes. Semantic Taskscoord_inv.txt Binary task asking to distinguish between original sentence (class O) and sentences where the order of two coordinated clausal conjoints has been inverted (class I). An example of the latter is: “由于 古代 因此 有 不 少 人 是 做 了 舅舅 名义 而 封侯 致富 ， 舅舅 是 母亲 家 族 的 权力 代表 “. conj_inv.txt Binary task asking to distinguish between original sentence (class O) and sentences where the order of two coordinating conjunctions(CC) has been inverted (class I). An example of the latter is: “其 设计 目标 为 简单 并 有 高 易用性 ， 且 在 开放 街 图 的 主要 页面 上 作为 预设 的 编辑器 “.Chinse POS tagging are done by thunlp/THULAC-Python .]]></content>
      <categories>
        <category>Research</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿姆达尔定律]]></title>
    <url>%2F2019%2F10%2F16%2F%E9%98%BF%E5%A7%86%E8%BE%BE%E5%B0%94%E5%AE%9A%E5%BE%8B%2F</url>
    <content type="text"><![CDATA[Paper Reading Note——Uses and abuses of Amdahl’s law Abstract本文介绍了并行计算领域的两大定律——阿姆达尔定律和古斯塔夫森定律，并以简练的证明指出古斯塔夫森对阿姆达尔定律的驳斥有误，在实际上两个定律是等效的，定律的使用需要统一参数f(串行部分所占比例)的定义才不至于导致错误。因此阿姆达尔定律事实上并没有被推翻，它还在内存结构设计和指令集设计上有重要的指导意义。 Two Conflicting Laws?阿姆达尔定律是阿姆达尔在1967年提出的关于串行部分占比对程序并行加速比的影响，公式是： S = \frac{1}{f +(1-f)/N}S为加速比，N为并行处理器的数量，f为程序中串行（不可并行）部分的占比。当程序的所有部分都可并行时，就可达到线性加速比N。当N趋于无穷时，S的上界是$\frac{1}{f}$ ，如果我们假设f固定为0.2那么不管处理器有多少，加速比最高为5—— 这样的结论无疑是带有悲观色彩，而且看起来和许多大规模并行计算实验中出现的近似线性加速比相悖。古斯塔夫森认为阿姆达尔定律对大规模并行计算是不适用的，Baria提出古斯塔夫森定律，加速比的计算被更改为： S = g+(1-g)/N其中g的定义是一个并行系统中串行部分任务的时间占比。而作者引用Yuan Shi的观点指出，阿姆达尔定律和古斯塔夫森定律的条件中f和g的定义其实是不同的，古斯塔夫森定律只是阿姆达尔定律的一个变式，是人们对阿姆塔尔定律中f的高估导致了阿姆塔尔定律错误的表象。 The Equivalence of the Two LawsYuan Shi在1996年指出，阿姆塔尔定律和古斯塔夫森定律事实上是等价的，表面上的矛盾来源于f和g的定义不同。本文对这部分证明说得不甚清楚，我查阅了Yuan Shi的原作Reevaluating Amdahl’s Law and Gustafson’sLaw ，他指出，在阿姆达尔定律中，比例f是指串行部分在只有一个处理器情况下占总时间的比例，即 f = \frac{t_s }{t_s + t_p(1)}而在古斯塔夫森定律中，g是指有N个处理器时串行部分占总时间的比例，即： g = \frac{t_s}{t_s+t_p(N)}两者的关系是： f = \frac{1}{1+(1-g)*N/g}如果把g当成f代入阿姆达尔定律，f就被严重高估了，因此会得到不正确的较低加速比。比如，古斯塔夫森用于证伪阿姆达尔定律的例子是：g=0.004，N=1024,实验中加速比在1000倍左右，将g代入古斯塔夫森定律得到加速比S=1020，而将g当作f代入阿姆达尔定律只能得到S=201。殊不知，他搞错了阿姆达尔定律的条件，代入的应该是对应的f=0.0000039，同样能S=1020的近似线性加速比。因此阿姆塔尔定律并没有问题，只是许多人在应用时混淆了定义，严重高估了f的值导致的。 因此，在衡量并行计算对性能的提升时一定要定义好条件和metric。有一个类似的错误是：N个元素在单个处理器上选择排序的复杂度是$N^2$,如果划分为K份，用K个处理器进行并行的选择排序再归并，复杂度将是$N+(N/K)^2+N*(K-1)$,那么加速比是： S = \frac{N^2}{N+(N/K)^2+N*(K-1)}= \frac{1}{1/N + 1/K^2 + (K-1)/N}当N很大时就得到了令人疑惑的$K^2$加速比。事实上，并行时运行的是归并排序(只划分一次就做选择排序然后归并的形式)，而串行时是单纯的选择排序，用不同的算法比较是不公平的。如果串行时也用类似的归并排序，加速比将是： S = \frac{N+K*(N/K)^2+N*(K-1)}{N+(N/K)^2+N*(K-1)} 当N很大时S接近K，也就是正常的线性加速比。 Applications of Amdahl’s lawMemory Hierarchy Design一级缓存的加速比可以用类似阿姆达尔定律的式子表示： S = \frac{T_m/T_c}{h+(1-h)T_m/T_c} h为缓存命中率，$T_m、T_c$分别为主存访问时间和cache访问时间 ISA and Processor Design对系统某部分性能改进带来的加速比是: S = \frac{Execution \ time \ before \ a \ feature \ is \ improved }{Execution \ time \ after \ a \ feature \ is \ improved}举一个例子，如果改进前乘法指令用时占比是40%,改进乘法指令使其比原来快K倍，则加速比为 S = 100/(60+40/K)不管K有多大,$S &lt; 100/60 = 1.67$。这就启示我们，不管怎样优化系统中重要而常用的部分，总是有其他部分会成为瓶颈，流水线中最慢的一级决定了整个系统的效率。 Conclusions and My Thoughts阿姆塔尔定律的悲观和古斯塔夫森定律的乐观在实质上是等价的，阿姆达尔定律在并行加速、指令系统设计等领域具有重要的启发意义，也告诫我们木桶最短的一块板决定了它的容量，做人做事要有所长，也不能有过分的短处，否则发展的高度将受到限制。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Work Hard and Productively]]></title>
    <url>%2F2019%2F09%2F23%2FWork-Hard-and-Productively%2F</url>
    <content type="text"><![CDATA[“It’s not so much how busy you are, but why you are busy. The bee is praised, the mosquito is swatted.”- Mary O’Connor]]></content>
  </entry>
  <entry>
    <title><![CDATA[Vscode Remote支持jupyter]]></title>
    <url>%2F2019%2F09%2F22%2FVscode-Remote%E6%94%AF%E6%8C%81jupyter%2F</url>
    <content type="text"><![CDATA[之前在服务器上做数据可视化，需要开jupyter notebook再打洞访问，今天发现vscode remote已经支持直接写jupyter,效果如图：]]></content>
  </entry>
  <entry>
    <title><![CDATA[pytorch多卡训练]]></title>
    <url>%2F2019%2F09%2F20%2Fpytorch%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83%2F</url>
    <content type="text"><![CDATA[做实验时使用了较大的预训练模型，超过了单张显卡的memory而报错，学习到了多卡训练的方式： 设备中存在多卡的条件下: 最简单的方法是直接使用torch.nn.DataParallel将模型wrap一下即可：123456net = torch.nn.DataParallel(model)# 这时，默认所有存在的显卡都会被使用。~~~ 如果机子中有很多显卡(例如有八张显卡)，但我们只想使用0、1、2号显卡，那么我们可以：~~~pythonnet = torch.nn.DataParallel(model, device_ids=[0, 1, 2]) 或者这样： os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &#39;,&#39;.join(map(str, [0,1,2])) net = torch.nn.DataParallel(model) CUDA_VISIBLE_DEVICES 表示当前可以被python环境程序检测到的显卡很简单的操作，这样我们就可以比较方便地使用多卡进行训练了]]></content>
      <categories>
        <category>编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[元学习Meta Learning 调研综述]]></title>
    <url>%2F2019%2F09%2F17%2F%E5%85%83%E5%AD%A6%E4%B9%A0Meta-Learning-%E8%B0%83%E7%A0%94%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Meta Learning ABCAn overview of the meta learning research area for beginners. Thanks to the tutorial Meta-Learning: from Few-Shot Learning to Rapid Reinforcement Learning by Chelsea Finn and Sergey Levine and other references are listed in the middle of the tutorial. Let’s immerse ourselves in the world of meta learning :flags: . Part 0: Popular Public Resources in Meta LearningThanks to the curated list by Sudharsan Ravichandiran in the repo Awesome-Meta-Learning Lecture Videos Chelsea Finn: Building Unsupervised Versatile Agents with Meta-Learning Sam Ritter: Meta-Learning to Make Smart Inferences from Small Data Model Agnostic Meta Learning by Siavash Khodadadeh Meta Learning by Siraj Raval Meta Learning by Hugo Larochelle Meta Learning and One-Shot Learning DatasetsMost popularly used datasets: Omniglot mini-ImageNet ILSVRC FGVC aircraft Caltech-UCSD Birds-200-2011 Workshops MetaLearn 2017 MetaLearn 2018 MetaLearn 2019 Researchers Chelsea Finn, _UC Berkeley_ Pieter Abbeel, _UC Berkeley_ Erin Grant, _UC Berkeley_ Raia Hadsell, _DeepMind_ Misha Denil, _DeepMind_ Adam Santoro, _DeepMind_ Sachin Ravi, _Princeton University_ David Abel, _Brown University_ Brenden Lake, _Facebook AI Research_ Popular Paper Reading Lists https://github.com/sudharsan13296/Awesome-Meta-Learning https://github.com/floodsung/Meta-Learning-Papers Part 1 : Problem Statement1.1 Aim: Learning to learnMeta-learning, also known as “learning to learn”, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples. It looks very similar to a normal learning task, but one dataset is considered as one data sample. 1.2 How to train Our training procedure is based on a simple machine learning principle: test and train conditions must match” Vinyals et al., Matching Networks for One-Shot Learning The general principle is to reserve a test set for each task,so we can learn meta parameters $\theta$ to generate specific model parameters $\phi$ rapidly to fit well for a new task. To cover it in one formula: 1.3 Closely related areas Multi-task Learning: Hyper parameter Optimization: hyper parameters can be seen as $ \theta$,NN weights can be seen as $ \phi $ Neural architecture Search(NAS): architecture can be seen as $\theta$,NN weights can be seen as $\phi$ Part 2: Overview: Meta Learning AlgorithmsGeneral Recipe： Choose a form of $p(\phi_i | D_i^{tr},\theta)$ Choose how to optimize $\theta$ w.r.t max-likehood objective using $D_{meta-train}$ Black-box adaptation Optimization-based inference Non-parametric methods Bayesian meta-learning 2.1 Black-box AdaptationDefinitionTrain a neural network to represent $p(\phi_i|D_{i}^{tr},\theta)$，to simplify it ,use deterministic $\phi_i = f_{\theta}(D_i^{tr}) $ (non Bayesian way) Possible forms of $f_{\theta}$ (all kinds of NN)： LSTM Neural turing machine (NTM) 1-D convolutions feed forward + average Challenges and Possible SolutionsOutput all neural net parameters does not seem scalable. Idea: Do not need to output all parameters of neural net, only sufficient statistics. Please read the two papers listed below. Papers to read Meta-Learning with Memory-Augmented Neural Networks A SIMPLE NEURAL ATTENTIVE META-LEARNER 2.2 Optimization-based inferenceDefinitionAcquire $\phi_i$ through optimization: $ max_{\phi_i} log p (D_i^{tr}|\phi_i) + log p (\phi_i | \theta)$ Meta-parameter $\theta$ serves as a prior,e.g initialization for fine-tuning Other forms of prior: explicit Gaussian prior: Meta-Learning with Implicit Gradients Bayesian linear regression on learned features: Meta-Learning Priors for Efficient Online Bayesian Regression Closed-form or convex optimization on learned features:Meta-learning with differentiable closed-form solvers, Meta-Learning with Differentiable Convex Optimization Contrast: Optimization vs. Black-Box Adaptation Papers to read A Simple Neural Attentive Meta-Learner Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm MAML approximates hierarchical Bayesian inference Challenges and Possible Solutions How to choose architecture that is effective for inner gradient-step? idea： Progressive neural architecture search + MAML see: Auto-Meta: Automated Gradient Based Meta Learner Search Second-order meta-optimization can exhibit instabilities 2.3 Non-parametric methodsDefinitionUse parametric meta-learners that produce effective non-parametric learners. See: Matching Networks for One Shot Learning Challenges and possible solutionsWhat if you need to reason about more complex relationships between data points? Learn non-linear relation module on embeddings : Learning to Compare: Relation Network for Few-Shot Learning Learn infinite mixture of prototypes : Infinite Mixture Prototypes for Few-Shot Learning Perform message passing on embeddings: FEW-SHOT LEARNING WITH GRAPH NEURAL NETWORKS 2.4 Compare and Extend 2.5 Bayesian meta-learningBackgroundFew-shot learning problems may be ambiguous. It’s important for these situations: safety-critical few-shot learning ( e.g. medical imaging) Active learning: Active One-shot Learning Learning Active Learning from Data Learning Algorithms for Active Learning learning to explore in meta-RL Key Idea Papers to Read Meta-Learning Probabilistic Inference For Prediction Amortized Bayesian Meta-Learning Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm Bayesian Model-Agnostic Meta-Learning Modulating transfer between tasks in gradient-based meta-learning Probabilistic Model-Agnostic Meta-Learning Part 3: Meta-learning applicationsApplications in computer vision : Few-shot image recognition Vinyals et al. Matching Networks for One Shot Learning Human motion and pose prediction Gui et al. Few-Shot Human Motion Prediction via Meta-Learning Alet et al. Modular Meta-Learning Domain adaptationcom Li, Yang, Song, Hospedales. Learning to Generalize: Meta-Learning for Domain Adaptation Few-shot segmentation Shaban, Bansal, Liu, Essa, Boots. One-Shot Learning for Semantic Segmentation Rakelly, Shelhamer, Darrell, Efros, Levine. Few-Shot Segmentation Propagation with Guided Networks Dong, Xing. Few-Shot Semantic Segmentation with Prototype Learning Applications in image &amp; video generation : Few-shot image generation Reed, Chen, Paine, van den Oord, Eslami, Rezende, Vinyals, de Freitas. Few-Shot Autoregressive Density Estimation Few-shot image-to-image translation Liu, Huang, Mallya, Karras, Aila, Lehtinen, Kautz. Few-Shot Unsupervised Image-to-Image Translation Generation of novel viewpoints Gordon, Bronskill, Bauer, Nowozin, Turner. VERSA: Versatile and Efficient Few-Shot Learning Generating talking heads from images Zakharov, Shysheya, Burkov, Lempitsky. Few-Shot Adversarial Learning of Realistic Neural Talking Head Models Applications in NLP : Adapting to new programs Neural Program Meta-Induction Natural Language to Structured Query Generation via Meta-Learning Adapting to new language Meta-Learning for Low-Resource Neural Machine Translation Learning new words Matching Networks for One Shot Learning Adapting to new personas Personalizing Dialogue Agents via Meta-Learning Some more applications : One-hot imitation learning One-Shot Imitation Learning Task-Embedded Control Networks for Few-Shot Imitation Learning One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks Learn from weak supervision One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning Chelsea Finn - Berkeley bCourses Part 4: Meta-reinforcement learningWhy should we care about meta-RL? People can learn new skills extremely quickly, and we never learn from scratch. Maybe meta-RL algorithms can learn much more efficiently. Basic about RLMarkov decision process $M=\{S,A,P,r\}$ $S$ - state space states $s \in S$ (discrete or continuous) $A$ - action space actions $a \in A$ (discrete or continuous) $P$ - transition function i.e. $p(s_{t+1}|a_t,s_t)=P(s_t,a_t,s_{t+1})$ $r$ - reward function $r:S \times A \rightarrow \mathbb{R}$ eg: $r(s_t,a_t)$ - reward $\pi_\theta(a|s)$ - policy with params $\theta$ $\theta^\star=\arg \max_\theta E_{\pi_\theta}[\sum_{t=0}^Tr(s_t,a_t)]$ About the policy: finite horizon :\theta^\star=\arg \max_\theta E_{\pi_\theta}[\sum_{t=0}^Tr(s_t,a_t)] infinite horizon with discounted return :\theta^\star=\arg \max_\theta E_{\pi_\theta}[\sum_{t=0}^{\infty}\gamma^t r(s_t,a_t)] stationary distribution :\theta^\star=\arg \max_\theta E_{\pi_\theta(s,a)}[r(s_t,a_t)] consider $\pi_\theta(\tau)=p_\theta(s_1,a_1,…,s_T,a_T)=p(s_1)\prod_{t=1}^T\pi_\theta(a_t|s_t)p(s_{t+1}|s_t,a_t)$ We get $\theta^\star=\arg \max_\theta E_{\pi_\theta(\tau)}[R(\tau)]$ Here is the whole picture: Review about Meta-learningthe dataset : $D_{meta-train}=\{(D_1^{tr},D_1^{ts}),…,(D_n^{tr},D_n^{ts})\}$ the training set : $D_i^{tr}=\{(x_1^i,y_1^i),…,(x_k^i,y_k^i)\}$ the test set :$D_i^{ts}=\{(x_1^i,y_1^i),…,(x_l^i,y_l^i)\}$ Meta-learning is tring to learn $\theta$ such that $\phi_i = f_\theta(D_i^{tr})$ is good for $D_i^{ts}$ Probabilistic view : \theta^\star = \arg \max_\theta \sum_{i=1}^n\log p (\phi_i|D_i^{ts}) \quad where\ \phi_i = f_\theta(D_i^{tr})Deterministic view : \theta^\star = \arg \min_\theta \sum_{i=1}^n \mathcal{L} (\phi_i,D_i^{ts}) \quad where\ \phi_i = f_\theta(D_i^{tr})The meta RL problemThink about these four problems: The “Generic” learning (determinstic view)\theta^\star = \arg \min_\theta \sum_{i=1}^n \mathcal{L} (\theta,D_i^{ts}) = f_{learn}(D^{tr}) The “Generic” meta-learning (determinstic view)\theta^\star = \arg \min_\theta \sum_{i=1}^n \mathcal{L} (\phi_i,D_i^{ts}) \quad where\ \phi_i = f_\theta(D_i^{tr}) Reinforcement learning\theta^\star = \arg \max_\theta E_{\pi_\theta(\tau)}[R(\tau)]=f_{RL}(\mathcal{M}) \quad \mathcal{M} = \{S,A,P,r\} Meta-reinforcement learning\theta^\star = \arg \max_\theta \sum_{i=1}^n E_{\pi_{\phi_i}(\tau)}[R(\tau)] \quad where \ \phi_i = f_\theta(\mathcal{M}_i) Consider the meta-RL, at the training time, we assumpt $\mathcal{M}_i\sim p (\mathcal{M})$ At meta test-time, sample $\mathcal{M}_{test}\sim p(\mathcal{M})$, get $\phi_i = f_\theta(\mathcal{M}_{test})$ Meta-RL with recurrent policiesReconsider $\theta^\star = \arg \max_\theta \sum_{i=1}^n E_{\pi_{\phi_i}(\tau)}[R(\tau)] \quad where \ \phi_i = f_\theta(\mathcal{M}_i)$ The main question about meta-RL is how to implement $f_\theta(\mathcal{M}_i)$. What should $f_\theta(\mathcal{M}_i)$ do ? improve policy with experience from $\mathcal{M}_i$ - $\{(s_1,a_1,s_2,r_1),…,(s_T,a_T,s_{T+1},r_T)\}$ choose how to interact, i.e. choose $a_t$ Actually, we just train a RNN policy! \theta^\star=\arg \max_\theta E_{\pi_\theta}[\sum_{t=0}^Tr(s_t,a_t)]Optimizing total reward over the entire meta-episode with RNN policy automatically learns to explore! Architectures for meta-RL standard RNN(LSTM) architectureDuan, Schulman, Chen, Bartlett, Sutskever, Abbeel. RL2: Fast Reinforcement Learning via Slow Reinforcement Learning. 2016. attention + temporal convolution Mishra, Rohaninejad, Chen, Abbeel. A Simple Neural Attentive Meta-Learner. parallel permutation-invariant context encoder Rakelly, Zhou, Quillen, Finn, Levine. Efficient Off-Policy Meta-Reinforcement learning via Probabilistic Context Variables MAMLLet’s rethink the equation \theta^\star = \arg \max_\theta \sum_{i=1}^n E_{\pi_{\phi_i}(\tau)}[R(\tau)] \quad where \ \phi_i = f_\theta(\mathcal{M}_i). For standard RL problem, we can update the $\theta$ this way : \theta^\star=\arg \max_\theta E_{\pi_\theta(\tau)}[R(\tau)]=\arg \max_\theta J(\theta) \\ \theta^{k+1}\leftarrow \theta^k + \alpha \nabla_{\theta^k}J(\theta^k)But if $f_\theta(\mathcal{M}_i)$ is an RL algorithm: $f_\theta(\mathcal{M}_i) = \theta + \alpha \nabla_\theta J_i(\theta)$ we requires interacting with $\mathcal{M}_i$ to estimate $\nabla_\theta E_{\pi_\theta}[R(\tau)]$. And this is model-agnostic meta-learning (MAML) for RL! Picture for MAML: Algorithm: For RL problem, we need to change the $\mathcal{L}$. So we update $\theta$ use $\theta \leftarrow \theta + \beta \sum_i \nabla_\theta J_i[\theta + \alpha \nabla_\theta J_i(\theta)]$ Something more on MAML/gradient-based meta-learning for RL: Better MAML meta-policy gradient estimators: Foerster, Farquhar, Al-Shedivat, Rocktaschel, Xing, Whiteson. DiCE: The Infinitely Differentiable Monte Carlo Estimator. Rothfuss, Lee, Clavera, Asfour, Abbeel. ProMP: Proximal Meta-Policy Search. Improving exploration: Gupta, Mendonca, Liu, Abbeel, Levine. Meta-Reinforcement Learning of Structured Exploration Strategies. Stadie, Yang, Houthooft, Chen, Duan, Wu, Abbeel, Sutskever. Some Considerations on Learning to Explore via Meta-Reinforcement Learning. Hybrid algorithms (not necessarily gradient-based): Houthooft, Chen, Isola, Stadie, Wolski, Ho, Abbeel. Evolved Policy Gradients. Fernando, Sygnowski, Osindero, Wang, Schaul, Teplyashin, Sprechmann, Pirtzel, Rusu. Meta-Learning by the Baldwin Effect. Meta-RL as partially observed RLWhat’s partially observed markov decision processes (POMDPs) ? $\mathcal{M} = \{S,A,O,P,\epsilon,r \}$ $O$ - observation space observations $o \in O$ (discrete or continuous) $\epsilon$ - emission probability $p(o_t|s_t)$ In $\pi_\theta(a|s,z)$, we think $z$ is the information policy needs to solve the current task. So learning a task is equivalent to inferring $z$ form the context $(s_1,a_1,s_2,r_1),…$ . We can change the MDP to a POMDP ! $\tilde{\mathcal{M}} = \{\tilde S ,A,\tilde O,\tilde P,\epsilon, r\}$ $\tilde S = S \times Z$ $\tilde s = (s,z)$ $\tilde O = S$ $\tilde o = s$ So solving the POMDP $\tilde{\mathcal{M}}$ is equivalent to meta-learning. To solve it, we need to estimate $p(s_t|o_{1:t})$ or $p(z_t|s_{1:t},a_{1:t},r_{1:t})$. We can exploring via posterior sampling with latent context by doing the following two steps: sample $z \sim \tilde p (z_t|s_{1:t},a_{1:t},r_{1:t})$ act according to $\pi_\theta(a|s,z)$ to collect more data It is not optimal, but it’s pretty good both in theory and in practice! Perspectives on meta-RL Advantages Disadvantages RNN -conceptually simple -relatively easy to apply -vulnerable to meta-overfitting -challenging to optimize in practice Bi-level optimization -good extrapolation (“consistent”) -conceptually elegant -complex, requires many samples Inference problem -simple, effective exploration via posterior sampling -elegant reduction to solving a special POMDP -vulnerable to meta-overfitting -challenging to optimize in practice Model-based meta-RLIdea: improve $\pi_\theta$ implicitly via model $\hat{p}(s_{t+1}|s_t,a_t)$ Advantages: requires much less data vs model-free a bit different due to model can adapt extremely quickly Papers to read: Saemundsson, Hofmann, Deisenroth. Meta-Reinforcement Learning with Latent Variable Gaussian Processes. Nagabandi, Finn, Levine. Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL. Nagabandi, Clavera, Liu, Fearing, Abbeel, Levine, Finn. Learning to Adapt in Dynamic, Real-World Environments Through Meta-Reinforcement Learning. ICLR 2019. ChallengesMeta-OverfittingCause of overfitting: Meta learning requires task distributions, while specifying task distributions is hard when we have few meta-training tasks. Possible Algorithms: Algorithm Advantages Disadvantages black-box adaptation simple and flexible models relies entirely on extrapolation of learned adaptation procedure optimization-based at worst just gradient descent pure gradient descent is not efficient without benefit of good initialization non-parametric at worst just nearest neighbor does not adapt all parameters of metric on new data (might benearest neighbor in very bad space) unsupervised meta-learning solve tasks efficiently and don’t need hand-specified labels \ Papers to read: Hsu, Levine, Finn. Unsupervised Learning via Meta-Learning. ICLR 2019 Gupta, Eysenbach, Finn, Levine. Unsupervised Meta-Learning for Reinforcement Learning. Eysenbach, Gupta, Ibarz, Levine. Diversity is All You Need. Gupta, Eysenbach, Finn, Levine. Unsupervised Meta-Learning for Reinforcement Learning. Hsu, Levine, Finn. Unsupervised Learning via Meta-Learning. Khodadadeh, Boloni, Shah. Unsupervised Meta-Learning for Few-Shot Image and Video Classification. Metz, Maheswaranathan, Cheung, Sohl-Dickstein. Meta-Learning Update Rules for Unsupervised Representation Learning. Ren, Triantafillou, Ravi, Snell, Swersky, Tenenbaum, Larochelle, Zemel. Meta-Learning for Semi-Supervised Few-Shot Classification. MemorizationProblem: If the task data isn’t strictly needed to learn the task, how to trade off information? Possible way to solve: Provide demonstration and trials/language instruction/goal image/video tutorial. Paper to read: -Zhou et al. Watch-Try-Learn: Meta-Learning Behavior from Demonstrations and Rewards, ‘19 Ultimate Goal:Online Meta-LearningPaper to read:-Finn, Rajeswaran et al. Online Meta-Learning ICML ‘19]]></content>
  </entry>
  <entry>
    <title><![CDATA[序属新秋]]></title>
    <url>%2F2019%2F09%2F10%2F%E5%BA%8F%E5%B1%9E%E6%96%B0%E7%A7%8B%2F</url>
    <content type="text"><![CDATA[和好朋友约月饼~实习公司优秀的中秋福利~]]></content>
  </entry>
  <entry>
    <title><![CDATA[写在大三之前]]></title>
    <url>%2F2019%2F09%2F07%2F%E5%86%99%E5%9C%A8%E5%A4%A7%E4%B8%89%E4%B9%8B%E5%89%8D%2F</url>
    <content type="text"><![CDATA[写给自己的碎碎念在Megvii实习度过了两个多月的暑假，眼下要回到校园，继续课程-lab-实习-双学位的单核多线程模式了。暑假整日忙于在Brain++上炼丹或做着工程上的活，自己去年搭的这个blog已经很久没有更新了。重启服务器，修复了Admin和Mathjax的问题，贴上了几篇零碎的PaperReading后，忽然很想在这个没有什么人看的site上写一篇关于时光的碎碎念，来为逝去一半的本科生活留下一点印记。 Timeline: 问自己，我是谁 2017年的夏天，非常意外地选择了北大计算机系就学，当时不曾接触过coding，对AI的认识也仅限于那年血虐李世石和柯洁的AlphaGo,甚至不知CNN和RNN为何物。Freshman Year过得有些艰难，数度怀疑过是否选择了不适合自己的路。 大一暑假在暑期课和军训中浑浑噩噩地过去，本科第二年开始同时修读CS的专业课和国发院的经济学课程，也接触了两个专业的许多师长前辈。我开始意识到自己喜欢的是作为学问的经济学，给我带来热情的是美妙的模型和中国改革发展的道路探索，而不是充满交际与展示的职业道路。余淼杰老师为我们讲国际贸易，一再强调李嘉图模型就是”强强取其更强，弱弱取其次弱“，鼓励我们找到自己所长所爱，发挥自己的比较优势，并指出这个时代最大的市场、最好的机会还是在我们的祖国;林毅夫老师告诫我们不人云亦云，”做人要在有疑处不疑，做学问要在不疑处有疑“，并用精彩的新结构模型解释中国改革的成绩和挑战，我印象最深的教诲是，要做创造剩余的奉献者，而不是利用残余的计划体制以自肥，不管从事什么职业，一定要站对自己的位置，实现个体利益和社会利益的统一。追求私利没有任何问题，重要的是你做创造价值的人而不是利用体制漏洞侵占他人果实的人，这是我在《中国经济专题》课程中学到的最浅显而发人深醒的道理。 在逐渐意识到自己并不太想将人生耗费在金融业的职场上后，我还是逐渐回到了本专业的正轨，Python写得越来越熟练，也对Deep Learning和CV,NLP有了一点很浅的了解。开始尝试进入Lab学习和做一些辅助性的工作，对NLP和Deep Code Synthesis都有兴趣而涉足不深，接下来的第三年是确定方向的时候了。 暑假前不安分的我投了N份实习简历，最后有幸被旷视Megvii接纳，度过了一个非常充实难忘的暑假。在这里我开始接触最前沿的业务，开始体验Research的魅力和挑战，第一次参与到一个系统的工程中去，整个工作目前还是Under Way的状态，但我相信能助力完成Make Data Annotation Sexy and Accessible的目标,能为Power Human With AI的大梦想贡献一点点力量。 时光荏苒，前途漫长而机会稍纵即逝。愿两年后的今天，本科毕业时再续此文时没有遗憾，走出一条踏实的道路，迎接人生新阶段的挑战。 ×愿自己如北戴河海上的朝阳，蓬勃、温暖而不断向上。 关于生活两年来没有发展出什么特别的爱好，在零碎的闲暇里，除了看书、追夏《夏目友人帐》（大爱猫咪老师！），依然喜欢听着张韶涵的歌，追B站上一切有关她的视频，去五棵松听了她的演唱会，今年有了一定的独立收入，正为她的寓言演唱会筹划一场说走就走的旅行。韶涵早就不是自带流量、话题十足的那种明星了，我喜欢她天生励志、坚强积极的人生态度，喜欢她二十年如一日纯粹的歌声，当然也喜欢她作为一个女孩的柔媚娇俏，虽然我明白她的内核是一个强大无比的战士，一个独立不羁的阿刁。十年以来，她的歌声和笑容，一直是我隐形的翅膀，是我引路的风筝。她教会我面对无法避免的原生磨难，激励我倔强地不断证明自我，从低到泥土以下的位置不断向上，迎接人生的朝阳。关于家庭的一切，尽可能地用肩膀承担，尽力便无憾。 关于社交，我的依旧相信自己有翅膀，不需要太多互相吹捧点赞的朋友，有一二交心者足矣。经历过一点感情的挫折，我选择以所有的能量心无旁骛地打磨自己，很庆幸一路上也遇到了值得珍惜的朋友彼此关心爱护。我不会忘记穷冬烈风中的二十岁生日是谁来到我身边给我最暖的祝福，不会忘记那么多个夜晚给予彼此的激励，有一二知音足矣。 End在北京的第三个秋天开始前写下这些记忆，冗长而细碎，唯愿来年回头来看，尽是年轻的美好与希望，没有遗憾。前途似海，Just Go On .]]></content>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯生成式主动学习]]></title>
    <url>%2F2019%2F09%2F07%2F%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%94%9F%E6%88%90%E5%BC%8F%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Bayesian Generative Active Deep LearningPaper Reading Note URL: https://arxiv.org/pdf/1904.11643.pdf TL;DRICML2019上关于主动学习的新作，整合了用贝叶斯神经网络衡量预测不确定性的方法BALD、MCDropout和用GAN生成不确定样本的方法GAAL,将pool-based和query-synthesis的方法结合起来做ActiveLearning,只用40%的训练数据就在CIFAR上取得了91% 的准确率。虽然有拿他人方法排列组合的感觉，但阅读本文对了解AcitveLearning各方面的进展还是十分有益的。 Information below is optional; you can change/remove it if you like Related WorksGAAL &amp; BDA与传统的pool-based方法从unlabeled中选取有价值的样本交给人标注不同，GAAL（Generative Adversial Active Learning） 用GAN生成信息量大的“伪样本”交给人标注，同样能以较低的cost训练出好的模型，paper见Arxiv链接，我的note也在论坛上。 BDA(Bayesian Data Augmentation) 与之类似，都是如图的思路： BALD &amp; MC-Dropout之前Deep Learning和Active Learning较难结合有两个原因： DL需要大量带标签数据，而AL着眼的就是标注尽可能少的数据来训练好模型。 AL每次query时需要做uncertainty sampling ,而NN模型预测的不确定性没有很好的标准衡量。 Houlsby等人在2011年提出了贝叶斯不一致主动学习(Bayesian Active Learning by Disagreement,BALD),用贝叶斯神经网络做分类器能更好地衡量预测的不确定性，可以参看Bayesian Active Learning for Classification and Preference Learning，我简要概括如下： The central goal of information theoretic active learning is to reduce the number possible hypotheses maximally fast, i.e.to minimize the uncertainty about the parameters using Shannon’s entropy 即基于信息论的主动学习核心目标是快速地降低可能的假设数量，即根据香农熵最小化参数的不确定性，用式子表述是： arg min D' \ H( \theta | D') = - \int p (\theta | D')logp (\theta | D') d\theta这个问题是NP-hard,可用贪心近似,seek the data point x that maximises the decrease in expected posterior entropy不过参数$\theta$的维度高，计算代价大，it’s equivalent to the conditional mutual information between the unknown outputand the parameters,等效的方法是the objective can be rearranged to compute entropies in y space： i.e: 为了更好地计算这个aquisition function ，Gal等人在2017年提出具体抽样函数使用 Monte Carlo (MC) dropout 方法，可参见Deep Bayesian Active Learning with Image Data Algorithmsimplementation是一个四部分的系统： a classifier $c(x;\theta_C)$: an encoder $e(x;\theta_E)$ : a generator\decoder $g(z;\theta_G)$: a discriminator $d(x;\theta_D)$其中classifier可以是任意流行的CNN模型，生成部分使用的是VAE-ACGAN,损失定义与计算过程如下： 关键就是把GAAL和BAD 代表的生成式方法和Pool-Based的传统方法结合起来。 Experiments 实验对比的方法包括：贝叶斯生成式主动深层学习模型（AL w. VAEACGAN）、使用 BDA 的主动学习模型（AL w. ACGAN）、未使用数据增加处理的 BALD （AL without DA）、未使用主动学习方法的 BDA （BDA）以及随机生成样本的方法。 实验中使用的分类器：ResNet18、ResNet18pa 使用完整训练集和 10 倍数据扩充建模的 BDA 的实验结果作为所有其他方法的上限（BDA （full training））。本文提出的模型（AL w. VAEACGAN）效果优于使用 BDA 的主动学习模型（AL w. ACGAN）。这说明尽管 AL w. ACGAN 使用样本信息训练，但生成的样本可能不具有信息性，因此是无效样本。尽管如此，AL w. ACGAN 生成的样本分类性能仍然优于未使用数据增加处理的主动学习方法（AL without DA） 用40%的数据就在CIFAR10上取得了91%的accuracy(据我所知ResNet在CIFAR10上全监督的state of art是95%左右)，可见Bayesian Generative Active Deep Learning 还是能极大地利用样本信息、减小比标注代价的。 Thoughts这篇文章虽然是之前他人工作的组合，却有助于我们了解Active Learning近年来发展的全貌，用贝叶斯不一致性计算uncertainy和用GAN生成新样本都值得尝试用来改进我们目前的标注算法。]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Generative Adversarial Active Learning]]></title>
    <url>%2F2019%2F09%2F07%2FGenerative-Adversarial-Active-Learning%2F</url>
    <content type="text"><![CDATA[Generative Adversarial Active LearningPaper Reading Note URL: https://arxiv.org/pdf/1702.07956v5.pdf TL;DR第一篇用以GAN为代表的生成式方法来做Active Learning的文章,比较有开创性,,利用已标注数据,用GAN生成uncertainty值高的”假”样本加速模型训练,在许多情况下不差于传统上用真实样本做迭代的pool based active learning. Information below is optional; 啊 you can change/remove it if you like BasicsActive Learning在带标注数据有限、标注成本高的场景下，学习如何选取高质量的未标注样本交给人来标注以更新模型，在有限的cost budget下提高模型训练效果。 GAN生成模型G和判别模型D进行极大极小博弈，直到判别器难以区分生成数据和真实数据为止，由经典论文Generative Adversarial Networks提出。图像生成领域常用DCGAN，用CNN做判别模型，与CNN类似但相反的反卷积结构做生成模型。本文的实验就是用开源的DCGAN库实现。 Algorithm: GAAL作者提出Generative Adversial Active Learning，核心非常简明，就是人工标注少量随机选取的样本后，用DCGAN生成目前判别器相对不确定的新数据交给人去标注，由此迭代训练分类模型。 Experiments文章的实验相对单薄，是用SVM做分类器，DCGAN做判别器和生成器在MNIST，USPS和CIFAR上做二分类实验，但还是有一些有趣的insgihts.分三张图说明： $\Uparrow$ 在MNIST上训练迁移到USPS(另一个手写数字数据集)上测试，做5-7二分类，可以看出用GAAL(黑线)生成350个sample的效果甚至高于11000个真实样本的Full Supervised(红线)。$\Uparrow$ 同样的setting，但是是在MNIST上训练、MNIST上测试，同领域情况下GAAL的效果就不如$SVM_{active}$和Full Supervised,而且生成100个sample之后出现掉点,作者推测是由于训练集和测试集分布相似且相对简单的情况下,决策边界变化不大,GAAL倾向于停留在边界附近生成过多相似的样本破坏模型.$\Uparrow$在CIFAR上做实验时,由于特征更复杂、生成更难，有时会出现人难以判断的样本(只能选择抛弃)，不过GAAL的准确率仍然比Full Supervised和传统的Active Learning高。 Thoughts 为解决训练集和测试集分布相近时的问题，可以考虑加入diversity term GAN的各种变体可以尝试是否能涨点 实验不够solid,可以考虑用ResNet等NN模型做分类器在ImageNet等更大规模的数据集上做实验看是否work]]></content>
  </entry>
  <entry>
    <title><![CDATA[迁移学习综述笔记]]></title>
    <url>%2F2019%2F09%2F07%2F%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[迁移学习综述笔记Paper Reading Note URL: https://arxiv.org/pdf/1903.04687.pdf TL;DR19年所做的对迁移学习和域适应(作者统称为Transfer Adaptation Learning,TAL)的综述,总结了five key challenges of TAL以及TAL模型测试的12个benchmark.作者认为TAL研究的五大关键技术是: Instance Re-Weighting Adaptation,样本迁移,在源域中找到与目标域相似的数据，把这个数据的权值进行调整，使得新的数据与目标域的数据进行匹配，然后加重该样本的权值，使得在预测目标域时的比重加大 Feature Adaptation,特征适应,意在为不同域的数据找到共同的特征表示方法 Classifier Adaptation,分类器适应,利用source domain的大量带标注数据和target domain的少量带标注数据学习一个generic classifier Deep Network Adaptation,DNN适应,研究如何将DNN学习到的特征在不同领域间迁移 Adversial Adaptation,对抗式适应,基于GAN的思想,使特征生成和域分类器进行对抗训练,直到两个领域的分布难以区分 五个领域细分的taxonomy我自己画了一张图概括,全文的信息量对刚接触TL的同学来说非常大,详细的介绍见note正文.个人认为对我们的工作意义较大的部分是DNN Adaptation和Adversial Adaptation, Information below is optional; you can change/remove it if you like Taxonomy of TAL Methods1.Instance Re-Weighting Adaptation样本迁移,在源域中找到与目标域相似的数据，把这个数据的权值进行调整，使得新的数据与目标域的数据进行匹配，然后加重该样本的权值，使得在预测目标域时的比重加大.单纯的Instance Re-Weighting方法适用于source与target 分布差距不大时,差距较大时Instance Weighting一般与其他技术共用.样本迁移的方法可分为三个子模型: 1.1 Intuitive Re-Weighting最早的朴素Instance Reweighting方法,即学习权重使source domain的数据分布接近target domain 1.2 Kernel Mapping Based Re-Weighting Intuitive Re-Weighting是在raw dataspace上操作的,而Kernel Mapping Based-ReWeighting是通过kernel mapping,使source和target在再生的希尔伯特核空间(RKHS)上距离最小化(距离衡量用MMD或KMM)做Distribution Mapping.核映射后两个域的边缘分布相似,但条件分布仍不同,可以利用Sample Selelction做进一步变换,可以利用cluster assumption做聚类,选取同一个cluster中标签相同的source samples,另一种方法是TJM model, 给变换矩阵加上范数正则项排除Outliers: 1.3 Co-training Based Weighting共同训练法, 首先分别在每个视图上利用有标记样本训练一个分类器；然后,每个分类器从未标记样本中挑选若干标记置信度(即对样本赋予正确标记的置信度)高的样本进行标记,并把这些“伪标记”样本(即其标记是由学习器给出的)加入另一个分类器的训练集中,以便对方利用这些新增的有标记样本进行更新。 2. Feature Adaptation2.1 Feature Subspace-Based利用子空间变换做无监督域适应,代表有sampling geodesic flow(SGF),geodesic flow kernel(GFK) and subspace alignment(SA),共同的假设是数据可在低维线性子空间表示,常用PCA做降维, 然后在子空间上做域适应,有两种思路: 利用Geodesic flow kernel,集成无穷多个子空间来模拟域的移动,代表方法有SGF和GFK,参见论文Geodesic Flow Kernel for Unsupervised Domain Adaptation subspace alignment,利用变换矩阵等方法直接对其\source和target的subspace对齐,代表方法有SA,SDA,GTH 2.2 Feature Transformation-Based对数据做变换或映射使source domain和target domain的分布尽量match.CV领域迁移学习的主流之一,可分为: Projection-Based:学习一个源域和目标域之间的映射矩阵最小化分布差异 Metric-Based: 在带标签的源域上学习一个合适的distance metric,使之也适用于目标域 Augementation-Based:特征增强方法,假设数据的特征可分为common,source specific,target specific三种,基于此进行数据增强 Zero Padding, 代表是HFA Generative Methods 生成数据加强domain transfer的鲁棒性,代表的文章是Adversarial Feature Augmentation for Unsupervised Domain Adaptation,训练两个GAN分别做数据增强和特征提取 2.3 Feature Reconstruction-Based利用source domain重建target domain以学习共同特征,排除outliers和噪音,对reconstruction矩阵加以rank或sparsity的限制以更好地学习两个领域的相关性 Low-rank Reconstruction, Sparsity Reconstruction 2.4 Feature Coding-BasedFeature Reconstruction是在两个领域的raw feature上学习reconstruction coefficients,而feature coding的方法注重于 seeking a group of basis (i.e., dictionary)and representation coefficients in each domain, 所以又称为域适应字典学习(domain adaptive dictionary learning). shared dictionary specific dictionary 2.5 Feature-Based Future Directions 在MMD之后,提出更好的similarity metric ensemble线性和非线性的域特征模型3. Classifier Adaptation分类器适应,利用source domain的大量带标注数据和target domain的少量带标注数据学习一个generic classifier 3.1 Kernel Classifier-Based基于核方法,一种思路是ASVM,在SVM中加一个bias item:另一种是基于multiple kernel learning(MKL), MMD based kernel matchingmetric $d_k^2()$ was jointly minimized with the structural risk based classifiers 3.2 Manifold Regularizer-Based流形正则化方法,有兴趣的同学可以参考经典论文Manifold Regularization： A Geometric Framework for Learning from Labeled and Unlabeled Examples.这种方法基于半监督学习的manifold assumption,即假设特征空间中距离近的样本属于同一类别的可能性较大.核心是挖掘边缘分布的几何形状,将其作为一个增加的正则化项,用了有监督和无监督样本共同来挖掘这一个数据分布的几何结构,这样训练出来的分类器就有更好的泛化性. 3.3 Bayesian Classifier-Based通过对先验知识建模弥补数据不足带来的泛化性能损失,本人对贝叶斯学习不够了解,有待阅读相关paper后补充: Kernelized Bayesian Transfer Learning Optimal classifiers with minimum expected error within a bayesian framework Bayesian Generative Active Deep Learning 4. Deep Network AdaptationDNN适应,研究如何将DNN学习到的特征在不同领域间迁移,个人认为这是迁移学习和我们的工作最相关的部分,基于instance,feature,classifer的方法都可以整合到这里来.作者列出了很多paper,本人认为与我们的工作密切相关且值得一读的有: How transferable are features in deep neural networks DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition Learning Transferable Features with Deep Adaptation Networks 作者将DNN Adaptation 分为三个子领域: 4.1 Marginal Alignment-Based边缘分布对齐,将source domain和target domain各层特征的MMD距离加入损失项,代表是DDC和DAN,模型可表述为:$J$是交叉熵损失函数,$\theta$是特征映射函数,$D^l$指网络在第l层输出的特征,边缘对齐$d^2_{ma}()$是边缘分布对齐的函数(即MMD).这个式子没有考虑网络在目标域的输出,可以用uncertainty minimization解决这个问题: 4.2 Conditional Alignment-Based在4.1的基础上多考虑语义信息,定义了与MMD类似的$d_{ca}$,将条件概率项加入到损失中 4.3 Autoencoder-Based用source data训练encoder,用decoder表征target data来做Adaptation.Stacked deep autoencoder用于TAL的General idea可以用这个式子表示: $f$是共用的encoder,$g$是共用的decoder,$z$是中间特征,$J$是reconstruction error(均方根误差),$\Omega$是衡量source和target feature分布差距的distribution discrepancy metric,$L$是带标签源域上的分类损失,$R$是参数正则项.$\Omega$可用KL散度表示,参见Supervised reparesentation learning: Transfer learning with deep autoencoders, 5. Adversial Adaptation对抗式适应,基于GAN的思想,使特征生成和域分类器进行对抗训练啊,直到两个领域的分布难以区分.作者介绍了三类方法,前两种是基于特征进行domain discrimination,第三种是用GAN生成target domain的图像. 5.1 Gradient Reversal-Based 与 Minimax Optimization-Based在网络中加入gradient reversal layer(GRL).模型由三部分构成:domain-invariant的特征表示模型,参数 $\theta_f $,图像分类器,参数$\theta_c$,域分类器,参数$ \theta_d $ .学习特征表示参数$\theta_f$时,最小化图像分类器的损失$L_c$,最大化域分类器的损失 $ L_d $ . 5.2 GAN-Based用GAN生成target domain的图像,代表工作有基于CycleGAN的CyCADA和DupGAN等. Thoughts这篇论文是非常详尽的迁移学习综述,其中DNN-Based和GAN-Based的方法非常契合数据标注论文的需要,值得进一步调研.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Paper Note: Face Recognition via Active Annotation and Learning]]></title>
    <url>%2F2019%2F07%2F15%2FPaper-Note-Face-Recognition-via-Active-Annotation-and-Learning%2F</url>
    <content type="text"><![CDATA[原文链接 最近开始研究Active Learning,正在阅读相关论文.本文针对带高质量标注的人脸数据集不足的问题,提出了一个比较简约的根据信息价值(VOI ),迭代选取标注样本并更新模型的系统,在使用少量标注数据的情况下在LFW和MS-Celeb-1M测试集上取得了与经典方法相当的效果. Motivation预处理不充分的数据集有两方面影响: 带错误标注和低质量图片的噪声影响模型的准确度 Multimodal类型(如landmarkpoints)的标注代价高,现有标注量不足 Main Ideas利用自己定义的信息价值(VOI, value of information),选取最有价值的未标注样本进行人工标注,更新模型,如此迭代,每个阶段的模型都能直接用来进行识别,准确性不断提高,当VOI 降到一定阈值一下时即停止采样,确定模型. VOL的定义与计算: $X_L$:已标注数据,$X_U$: 未标注数据,$X_P$:positive instances,$X_N$:negative instances 已标注数据的Risk: $r_p,r_n$ 为预定义的误预测损失($ r_p$是将正例预测为反例的损失,$r_n$相反),$p(x)$为现有的模型输出x为正例的概率 未标注数据的Risk: 和标注的cost加总,得到一个total risk函数: 作者假设标注代价相当,忽略之,得到候选用来标注钉未标注数据集S的VOI: Evaluation以CASIA-Webface为标注对象(训练集),仅用10%的训练数据量,在LFW测试集上取得了与经典方法相当的效果,而且第一次选取标注集后,每次选取的标注集不断减小,很快停止: 同样以CASIA-Webface为标注对象(训练集),在MS -Celeb-1M上测试,同样不逊色于使用全数据集训练的其他模型:]]></content>
  </entry>
  <entry>
    <title><![CDATA[Paper Notes——Deep Learning In Program Synthesis and Induction]]></title>
    <url>%2F2019%2F07%2F05%2FPaper-Notes%E2%80%94%E2%80%94Deep-Learning-In-Program-Synthesis-and-Induction%2F</url>
    <content type="text"><![CDATA[Neural program synthesis&amp;Induction的三篇入门论文，在期末过后的招生季,在往返南北的飞机上、酒店房间的小憩中断断续续地读下来，在此记之。 By Samuel Chen 2019.6 1.Recent Advances in Neural Program Synthesis综述性文章，介绍了Program Induction的概念、常见模型、它们的表现及改进方向，读毕对Program Induction领域有了大致的整体性把握。深度学习在CV和NLP等领域都取得了巨大突破，但在Program Synthesis上依然任重道远。 1.1 Introduction​ 方法 特点 Program Synthesis 显式返回程序，可读性强，但遇到很多瓶颈 Program Induction 引入Deep Learning，模拟性的黑盒，无法解读，Generality非常重要 深度学习的火爆让我们在程序生成领域也看到了希望，但程序生成和实体识别、机器翻译等问题有着一大不同，就是这些DL已大获成功的领域中，输入空间是连续的，可以用可微函数表示（因此可以使用梯度下降优化），只有数据的集合对人来说才有意义，如图像的像素点只有组合起来才有意义，而NLP领域中，字词虽然是离散的，DL却是通过学习连续的词向量起作用的。神经网络适于通过这种高维的、连续的状态空间表示离散的实体，这是人工智能中联结主义的观点。 而对我们关心的Program Synthesis领域，程序的每个原子结构都有其内在含义，不存在连续的状态空间，而由于字典较小和抽象性等原因，嵌入的办法也很难解决问题。由于训练数据是成对的输入/输出，神经网络无法学习具体的程序结构知识，联结主义在这里是有瓶颈的。 所以从1960年代起，早期的研究者多是遵循符号主义的观点，通过上下文无关语法树学习领域语言，进而构建有意义的程序。其缺点是学习本身不是直接的任务，目标不可微，不能用梯度下降优化。现有的方法实质上是求解约束可满足性问题，在尽可能缩小状态空间的前提下搜索解决方案。如模可满足性运算器(SMT solver)已在正确性和泛化能力上取得了突破。 时至今日，多数研究者认为符号主义和联结主义的互补才是程序生成的出路。人在符号控制方面是独一无二的，而信息处理的机制可以由联结主义的神经模型解决。好的Synthesis系统也应当如此，“where symbols are built up from embeddings of the program state space.” 1.2 Neural Program Induction Models1.2.1 基础——RNN &amp; LSTMRNN及其改进版本LSTM适合处理序列数据，双层LSTM形成的encoder-decoder结构不仅适于机器翻译，同样适用于输入输出不定长的Program Induction。以下介绍几种改进方向。 1.2.2 Convolutional Recurrence将CNN与GRU融合，代表作是Neural GPU，在循环神经网络的基础上，在每个神经元处加入卷积操作，以GRU为基础，以门控的CGRU为神经单元加入卷积操作，用3维向量嵌入表示hidden state，长度为n则经过n个CGRU单元输出，再进行解码。缺陷是每个时刻认为1个3D的状态向量包含之前所有的信息，可能无法真正利用之前1-t-1时刻的所有信息。 1.2.3 Attention借鉴机器翻译中常见的Attention机制，代表是Pointer-Net.此模型可解决比训练数据规模更大的测试问题，表现 出泛化性能的进步，但在大规模数据和corner cases上的性能表现无法保证。 1.2.4 Attention with memoryThe Neural Turing Machine (NTM)和Differentiable Neural Computer (DNC),加入外部存储，本质是发出读写命令的RNN controller，都是图灵完备的，但泛化能力和训练的方便程度都不如Pointer Net 1.2.5 Memory and Pre-Defined Primitives之前几种方案都是单纯的联结主义，而Neural Programmer 和 Neural RAM不直接对memory发出读写指令，而是对数据进行已显式定义好的一元或二元的基本运算，通过组合基本运算构成复杂程序。 组分： RNN Controller attention distributions memory unit Neural Programmer : take natural language inputs,is designed to be an automatic Question-Answering system that learns the latent programs required to answer its questions Neural RAM:creating highly compositional programs,can take hundreds of timesteps to complete,can create coherent programsthat span a much higher number of timesteps 1.2.6 Function Hierarchy之前提到的模型都是以输入-输出对作为训练数据，容易过拟合，监督太弱，不适于深度学习。Neural Programmer-Interpreter (NPI)通过增加模型复杂度和监督的粒度解决这个问题。最重要的改进是让函数通过创建新的栈帧（new stack frames）调用子函数，即调用新函数时将RNN的隐藏状态设为0，将新的程序嵌入向量、参数和上下文作为输入，返回母函数时通过A sigmoidal “return to caller” unit to terminate the current stack frame。问题是如何调用栈帧需要学习，对训练数据要求较高。作者提出的Neural Program Lattices (NPL)，通过a new neural network module uses dynamic programming estimate the likelihood of which stack frame the program exists，在更弱的监督下取得了与NPI相似的效果。 1.3 Analysis of Performance通过四个难度递增的任务评估各个模型。 1.3.1算术Neural GPU在二进制上表现出色，但十进制有问题，而且corner cases无法泛化。NPI和NPL在二进制和十进制加法都能handle，而且能通过Function Hierarchy学习进位操作，泛化性能更好。 1.3.2 数列操作NTM在20左右的小规模复制和排序上有良好表现，超过了传统的LSTM。Neural RAM在规模50左右的数列复制、翻转、轮换等操作都有良好表现，但不能很好排序,而NPI能很好地学习冒泡排序算法。 1.3.3 组合优化很多是NP难问题，普遍认为用神经网络处理嵌入表示更好解决。DNC目前能处理小规模的TSP问题。 1.3.4 Semantic Query Parsing缺乏严谨的大规模数据集 1.4 Strategies to Reshape Program Induction1.4.1 Structured Attention利用线性条件随机场，把握过去的状态集体间的关系 1.4.2 Hierarchical Memory利用二叉树等机构优化memory，加快速度 1.4.3 Enabling Recursion单纯的连接主义模型是无法进行递归调用的，Neural RAM和Neural Programmer只能使用事先定义好的操作，无法动态学习，只有Neural Programmer-Interpreter (NPI) is the only currently existing Neural Programming Architecture (NPA) that could support recursion.而且NPI的拥有可证明的泛化能力。 1.4.4 Greedy Algorithms强化学习的方法适合产生贪心解，并有较好的灵活性和泛化性能 1.5 Neural Program Synthesis1.5.1 Recent Examples Base: FlashFill NSPS:提出R3EE，将程序抽象为树状的RNN RobustFill：仍是带attention的s2s模型，make modifications to theDSL so as to increase the vocabulary by making compositional programs into literal ones Abstract Syntax Networks:the decoder which generates the AST is actually composed of several mutually recursive modules 1.5.2 Future Recommendations Specifically designing neural architectures NLP RL Reprsentation Learinng automation in learning meta optimization 2.Code Completion with Neural Attention and Pointer NetworksIJCAI2018的文章，针对语言模型无法处理OoV(out of vocabulary)的问题，提出了pointer mixture network 带Attention的LSTM生成词典内成分 pointer结构根据上下文补充Oov swicher决定何时用LSTM，何时用pointer 在JS和Python这两种动态类型语言数据集上测试，取得了state-of-arts效果。 具体实现： 2.1 程序表示：AST 结点含义 扁平序列化（增加两个bit） 程序生成→Seq2seq 2.2 Neural Language Model:LSTM Encoder-Decoder and Attention Mechanism Context Attention Parent Attention 2.3 Pointer Mixture 2.4 Experiments要点： 来自JS和Py的数据集 只对Value使用带Pointer的混合结构 评测指标：Accuracy 3.NEURAL SKETCH LEARNING FOR CONDITIONAL PROGRAM GENERATION3.1 概述ICLR2018的oral，提出解决根据标签条件（API calls and types）生成类Java语言代码的任务面临两大挑战： 语义与语法限制 低级特征阻碍学习 解决方案是一个叫BAYOU的系统，让神经网络学习生成满足语法要求的代码框架（忽略语义要求），is to learn not over source code, but over tree-structured syntactic models, or sketches, of programs，再通过组合方法补全低级的语义特征。生成可编译的代码。 目标： 实现： Label域X包含三类属性：API CALLS，OBJECT TYPES，KEYWORDS 思路：两种工具对应两类内容： Low level Features:主要是semantic的，these are relatively easy for a combinatorial,syntax-guided program synthesizer Syntax Features:主要是类型和API调用等语法信息 用树状结构表示，hypothesize should be relatively easy for a statistical learner 123graph LR X[X:Label] --&gt; Y[Y:Sketch] Y --&gt; Prog[Prog:Program] 3.2 Sketch Learning ——Gaussian Encoder-Decoder(GED) P(Y | X , \Theta) = \int_{Z \in R^m}P(Z|X,\Theta)P(Y|Z,\Theta) dZ 用到Jansen’s inequality，极大似然估计 $\Theta$ 3.3 Combinatorial Concretization a type-directed, stochastic search procedure that builds oncombinatorial methods for program synthesis]]></content>
  </entry>
  <entry>
    <title><![CDATA[城乡偏向和公共食堂导致的获取权丧失 ——1959-1961年饥荒成因浅探]]></title>
    <url>%2F2019%2F06%2F21%2F%E5%9F%8E%E4%B9%A1%E5%81%8F%E5%90%91%E5%92%8C%E5%85%AC%E5%85%B1%E9%A3%9F%E5%A0%82%E5%AF%BC%E8%87%B4%E7%9A%84%E8%8E%B7%E5%8F%96%E6%9D%83%E4%B8%A7%E5%A4%B1-%E2%80%94%E2%80%941959-1961%E5%B9%B4%E9%A5%A5%E8%8D%92%E6%88%90%E5%9B%A0%E6%B5%85%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[摘要本文从食品供应量下降和食物获取权这两个解释饥荒的角度出发，提出粮食产量下降并不必然导致饥荒，中央计划体制下权利分配不均的制度性因素才是导致59-61年饥荒的主要原因。在目前可掌握的实证下，可以认为统购统销制度与公共食堂制度并为重要的制度原因，不能简单地将饥荒归罪于其一，前者导致的城乡失衡与后者导致的农村内部失衡都可以解释饥荒的一部分成因，何为更主要的原因则有待更多数据支持计量研究得出。 一、食物获取权的影响大于供应下降在饥荒分析方面，传统认为的食品供应量的突然下降(Food Availability Decline，FAD)和阿马蒂亚·森提出的食物获取权理论是两条主要的思路。中国在1959-1961年的大饥荒伴随着农业生产力的突然崩溃（如图11），已有自然灾害说、公社制度说、管理不当说、一次性博弈说2等理论解释生产力滑坡的现象。 但本文的目的在于探讨饥荒现象的成因，食物供应量的下降在逻辑上并不是导致饥荒的充分条件。从城乡粮食消费量的历史数据（如图23）可以看出，饥荒开始的1959年农村人均粮食消费量（183.1）与1955年（185.7）差异不大，60、61年的农村人均粮食消费量虽降至历史低点，但基本与62、63年处于同一水平，直到1966年农村粮食供应才恢复到58年的水平，但事实上1962年饥荒现象在全国大多数地区已经结束了。也就是说，粮食供应量的恢复远迟于饥荒的结束———这就证明了简单地将饥荒归因于生产下降是极不合理的。 在计量研究方面，Lin与Yang在1999年以分省数据为基础，以农村人口比例和人均粮食产出分别代表各省的城乡偏向和粮食供应，对死亡率进行回归分析，指出各省死亡率的变差中，约69.5%是城乡偏向解释的4，以坚实数据证明了森的食物获取权理论框架在解释大饥荒时较传统的FAD更有说服力。在食物获取权理论的共识基础上，文贯中提出城乡偏向说无法解释为何持续40年的统购统销制度只在59-61年导致饥荒，认为无退出自由的公共食堂剥夺了农民的自主权利，导致极大的浪费和农村内部的阶层压迫，是触发和加剧饥荒的主要原因5。本文第二部分意图在比较两种观点的基础上探讨大饥荒的根本成因。 二、城乡偏向和公共食堂共同导致获取权失衡对林的城乡偏向说，文贯中认为1958年粮食的征购比并不算特别高（较1953年低），无法解释为何饥荒从1958年底开始6。笔者在分析历年粮食净征购比数据7的基础上（图3），发现粮食净征购比与饥荒有紧密的时序关系，1958-1960年的三年平均征购比处于绝对的历史高位，1959年粮食征购比飙升至远超历史平均的28%，次年全国粗死亡率近乎成倍增长，1961年粮食征购比下降到约为平均水平的17.5%，次年饥荒即告结束。这说明城乡粮食分配不均的制度性因素虽难以合理解释大饥荒在1958年底的突然爆发，却和饥荒的激化与结束有着可能存在的紧密联系。笔者认为，城乡偏向说的可能漏洞在于：第一，林的实证中简单地以城乡人口比例代表城乡偏向，由于各省执行征购政策的力度不同，这一代理变量难以真正代表农民相对城镇居民的食物获取权；第二，饥荒中农民食物获取权的失去不仅来自于城乡之间的失衡，农村内部的失衡在林的实证中被忽略了，而公共食堂假说恰好引入了农村内部的因素，可以解释饥荒的突然爆发。 公共食堂剥夺了农民通过自身劳动换取粮食的权利，而这是食物获取权中至关重要的核心。在该制度开始全面推行的1958年，出现了罕见的农村人均耗粮量远高于城市的情况———免费供应带来的需求剧烈上涨导致了极大的浪费，极有可能是触发该年底和次年初粮荒的原因（但浪费程度有待于逐月储粮量等数据的实证）。粮荒开始后，如果公共食堂能保证分配相对公平，是有避免大量非正常死亡之可能的。但公共食堂这一自上而下建立的乌托邦体制中，持有分配权的是非民选的干部和管理员，口粮的集体化导致普通农民”交换性权利”的缺失，难以生产自救，而集体分配普遍存在的阶层与职位压迫现象更是将普通农民推向了死亡线。公共食堂说在逻辑上是可以自洽的，公共食堂制度的建立（1958）和最终取消（1961）也和饥荒的起止吻合，但公共食堂制度实际执行中的持续时间、造成的浪费程度、农村内部不平等的程度等因素，在现有数据下难以量化衡量，应当将其和城乡偏向共同视为饥荒不断加剧的原因。 所以，现阶段审慎的观点应该是：中国1959-1961年大饥荒的根本原因是制度性因素导致部分农民的食物获取权丧失，而统购统销制度和公共食堂制度是两个主要的制度性因素，何者的影响更大有待于更多微观数据支持计量研究。 参考文献 1. 图片来源：《为何1959 —-1961 年大饥荒终结于1962 年》，范子英、孟令杰、石彗，《经济学》季刊2008年10月第8卷第1期 &#8617; 2. 《集体化和1959-1961年中国农业的崩溃》，林毅夫，《政治经济学评论》1990年第6期 &#8617; 3. 粮食消费量以贸易粮计算，资料来源：《中国商业年鉴１９８８》第716页，《中国商业年鉴１９９０》第592-3页，《中国商业年鉴１９９０》第XI-158页, 第XI-149页，《中国商业外经统计资料1952-1988》第51页。 &#8617; 4. 《食物供应量、食物获取权与中国1959-1961年的饥荒》，林毅夫、杨涛，英文版发于Economic Journal, Jan 2000,p136-152 &#8617; 5. 《中国三年大饥荒的触发及加剧之原因———论无退出自由的公共食堂的谋杀性后果》，文贯中，《当代中国研究》2009年第1期 &#8617; 6. 同引用5 &#8617; 7. 中华人民共和国农业部计划司编《中国农村经济统计大全: 1949-1986》( 北京: 农业出版社, 1989年5月) 第410-411页 &#8617; 8. 1959-1962年的全国粗死亡率分别为14.59‰、25.43‰、14.24‰、10.02‰，资料来源：中国国家统计局编《中国统计年鉴1999》，统计出版社，北京，1999 &#8617; 9. 阿马蒂亚·森提出饥荒更可能是由于权利分配不均造成的，这些权利包括四个方面：第一是以自己所拥有的物品交换食物的交换权，第二是以自己或雇佣的资源进行生产换取食物的生产权，第三是以自身劳动换取工资以获得食物的劳动权，第四是继承权，或获取他人，包括政府的赠予。前三个是基于市场的权利，可统称为交换性权利。森强调交换性权利突然减少对社会底层人民的打击。 &#8617;]]></content>
  </entry>
  <entry>
    <title><![CDATA[网络流求解不交路径数目问题]]></title>
    <url>%2F2019%2F06%2F07%2F%E7%BD%91%E7%BB%9C%E6%B5%81%E6%B1%82%E8%A7%A3%E4%B8%8D%E4%BA%A4%E8%B7%AF%E5%BE%84%E6%95%B0%E7%9B%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题问题：求有向图中任意两点间尽可能多的边不相交的路径数目以及尽可能多的点不相交的路径数目。 思路：转化为最大流问题。 引理引理:设 $ N = &lt; V,E,c,s,t &gt; $ 具有单位容量，|V| = n,|E|=m,最大流量为 $ v^ $,则N中s-t距离小于等于$2n/ \sqrt{v^}$.对N运行Dinic算法的时间为$O(n^{2/3}m)$。 证明：设N中s-t距离为l,$V_i$为与s距离为i的顶点集，$0≤i≤l-1$,则$v^ \leq c(V_i,V_{i+1} ) \leq |V_i| |V_{i+1}|)$, $0 \leq i \leq l-1$,则$V_i$和$V_{i+1}$中至少有一个顶点数不小于$\sqrt{v^}$,$n \geq \frac {d}{2}\sqrt{v^}$,$d \leq 2n / \sqrt{v^}$.运行Dinic算法时，由于单位容量，每个阶段的时间复杂度是$O(m)$,只需证阶段数为$O(n^{\frac{2}{3}})$。若$v^ \leq n^{\frac{2}{3}}$,显然成立;不然，考虑容量第一次超过$v^ - n^{\frac{2}{3}}$的阶段，这个阶段之后的阶段数显然不超过$n^{\frac{2}{3}}$,而这个阶段开始时的可行流f的容量不大于$v^ - n^{\frac{2}{3}}$,$N(f)$ 的最大流量不小于$n^{\frac{2}{3}}$,由上面的结论可知$N(f)$中s-t距离不大于$2n/ \sqrt{n^{\frac{2}{3}}}= 2n^{\frac{2}{3}}$,而每个阶段的s-t距离都大于前一个阶段的$s-t距离$，所以这个阶段之前最多有$2n^{\frac{2}{3}}$个阶段，总共最多有$3n^{\frac{2}{3}}+1$个阶段，证毕。 解决边不相交建立单位容量网络，转化为最大流问题，由引理知用Dinic算法求解复杂度为$O(n^{2/3}m)$. 点不相交拆点法建立简单单位容量网络，转化为最大流问题，用Dinic算法时间复杂度为$O(n^{1/2}m$]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>网络流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Acrobat Pro DC 过期问题]]></title>
    <url>%2F2019%2F06%2F06%2FAcrobat-Pro-DC-%E8%BF%87%E6%9C%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Acrobat Pro DC试用过期，只需要这样操作就能无限使用：将注册表文件替换 点击下载]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>日常 </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NSE简评]]></title>
    <url>%2F2019%2F05%2F21%2FNSE%E7%AE%80%E8%AF%84%2F</url>
    <content type="text"><![CDATA[本文为对新结构经济学理论的简要评述，在综述其基本原理与理论框架的基础上，结合学界评论以及林老师本人的回应，就政治制度缺位和产业政策的有效性这两个理论难点做出了讨论与展望,以希就正于师长与同学。 一、 要素禀赋、有效市场与有为政府——新结构经济学理论综述​ 在发展经济学领域，旧结构主义和新自由主义是两股主要思潮。旧结构主义认为经济结构外生决定，强调政府干预在产业结构升级中的决定作用，但由于赶超战略在发展中国家普遍失败，70年代后以新自由主义为基础的华盛顿共识成为主流。但随着以自由放任为特征的休克疗法在东欧失败和东亚经济崛起，结构、市场、政府的关系再次引起广泛思考。​ 在这样的背景下，林毅夫提出经济结构内生于要素禀赋结构，以要素禀赋为切入点将市场和政府的作用纳入新结构经济学（NSE）的框架，强调政府与市场的协同作用。以下从要素禀赋、市场配置、政府作用三方面阐述该学说的理论要点。​ 要素禀赋结构是新结构经济学的核心，整个理论框架实际上都基于如下假设：“一个经济体在每个时点上的产业和技术结构内生于该经济体在该时点给定的要素禀赋和结构。” 由于给定的要素禀赋结构决定了要素的相对价格，“一个企业的自生能力取决于产业、产品、技术选择是否符合要素禀赋结构决定的比较优势” ，因而与要素禀赋结构相适应的产业结构就是最优的，“经济发展的目标应该定位在要素禀赋结构的提升上” 。区别于旧结构主义关于“先进和落后”的二分看法，林认为经济发展“是一条从低收入农业经济向高收入工业经济的连续频谱” ，以本国的要素禀赋结构进行产业和技术选择，企业就具有自生能力，整个经济就能创造出最大的剩余，促使资本积累、要素禀赋结构提升，从而逐步实现产业结构的升级。​ 在市场和政府的作用方面，林提出了“有效市场、有为政府”。直接影响企业决策的是要素价格而不是禀赋结构本身，只有充分竞争的市场价格才能反映各要素的相对稀缺程度，因此市场是配置资源最有效率的机制。同时，在收集公共信息、基础设施建设等企业无法解决的问题上，政府可以起到补偿外部性的作用。在实际操作层面，林提出“增长甄别和因势利导框架”（GIFF, Growth Identification and Facilitation Framework），即政府要确定一国可能具有潜在比较优势的新产业并以适当的产业政策进行激励，起到因势利导的助推作用 。 二、 白壁微瑕，未来可期——理论难点探讨与展望​ 如第一部分述，新结构经济学的理论认为要素禀赋结构决定经济产业结构，强调市场的核心地位与政府的积极作用，在实证上能够解释历史上赶超战略、休克疗法的失败和以出口导向为基础的东亚经济崛起，被视为发展经济学第三波浪潮中的重要流派。在学界，对其的赞誉、质疑和批评兼有，政治制度的缺位、金融服务业的地位 、产业政策的有效性 、发展中国家的资本筹措 等问题都存在诸多争议。囿于笔者学识和篇幅限制，此文仅就两点简单探讨，以希抛砖引玉。​ 第一，NSE理论中政治制度缺位的问题。在GIFF框架中，政府理应扮演的是因势利导的角色，但NSE的整个论述并强调过政治制度。林基于理性人假设，认为领导人追求良好的经济绩效将使其个人效用最大化，因此领导者的自利并不影响GIFF的基础 。笔者认为在治理成绩之外，寻租也可以提升个人效用，即使深谙符合比较优势的少量补贴才是应行之事，政策制定者仍有可能利用产业政策寻租。林进一步辩护称,GIFF框架中“并不是由政府越俎代庖去决定一个国家应该发展什么产业”，产业升级取决于企业自主的选择，政府的作用只是帮助消除外部性瓶颈，不必担心寻租的问题 。此处依旧存在逻辑缺陷，政府只能起到因势利导的作用，而不是以大量补贴进行寻租，其前提是权力受到有效的监督和制衡，是需要政治制度作为保障的。林辩称“把我的主张简化成不需要制度改革是严重误读”“要审时度势推进制度改革，消除掉各种扭曲” ，但NSE理论中的确没有专门涉及政治制度的改革，似有过于简化之嫌。​ 理论可以接受简单假设，但实践中乌托邦式的幻想是危险的，没有民主法制保障的产业政策“可能加大市场扭曲、加重腐败” ，我国对光伏、电动车等产业的过度补贴也印证了这一危险性。依浅见，NSE的框架似可加入民主法制等政治基础因素，以更好地指导现实。​ 第二，产业政策的有效性问题。即使抛开寻租腐败问题，产业政策是否能真正起到因势利导的作用也是存在巨大争议的。以张维迎为代表的批评者认为，创新是不可预见的，“产业政策是披着马甲的计划经济”，创新只需要企业家在自由市场上不断试错 。林则回应称，发展中国家的产业升级有现成经验可资借鉴，同时在承认产品开发有赖于企业家精神的基础上，坚持基础研究、基础设施等外部性问题需要政府作为 。笔者认可后者在产业政策上不能因噎废食的观点，但GIFF框架中，潜在优势的产业如何选取有待深化研究，“从人均收入比自己高一两倍，过去二三十年发展得很好的国家现有的可贸易产业甄别选取”，且不说如何具体地甄别选取，现阶段满足这一条件的模仿对象已经找不到了——这就意味着基于NSE框架的发展理论还有待深化和完善，尤其要解决“政府如何可以通过在每个阶段上选择符合禀赋条件的发展政策快速实现在经济结构上与发达经济的收敛” 这一关键的实际问题。​ 瑕不掩瑜，作为新创立的发展理论，NSE已经在解释现实方面取得了巨大成功，现存的问题多属于有待深化和细化的细节与实践问题，沿着NSE的道路向前求索，定能发掘出有益于中国改革转型的理论财富，建立具有中国话语的理论体系。 参考文献 林毅夫.新结构经济学的理论基础和发展方向[J].经济评论,2017(03):4-16. 林毅夫.中国经济专题[M]. 北京:北京大学出版社, 2018.274-276. 林毅夫.新结构经济学——重构发展经济学的框架[J].经济学(季刊),2011,10(01):1-32. 林毅夫.新结构经济学[M]. 北京:北京大学出版社, 2014.135-138. 韦森.探寻人类社会经济增长的内在机理与未来道路——评林毅夫教授的新结构经济学理论框架[J].经济学(季刊),2013,12(03):1051-1074. 张维迎.为什么产业政策注定会失败[J].中国连锁,:,2016.11(1):84-88. 杨永华.评林毅夫的新结构经济学:理论、政策和难点[J].产经评论,2013,4(06):150-157. 林毅夫.繁荣的求索：发展中经济如何崛起[M]. 北京:北京大学出版社, 2012.34-36. 林毅夫.《新结构经济学》评论回应[J].经济学(季刊),2013,12(03):1095-1108. 林毅夫.中国经济专题[M]. 北京:北京大学出版社, 2018. 353-355. 余永定.发展经济学的重构——评林毅夫《新结构经济学》[J].经济学(季刊),2013,12(03):1075-1078. 林毅夫.中国经济专题[M]. 北京:北京大学出版社, 2018. 361-362. 张军.“比较优势说”的拓展与局限——读林毅夫新著《新结构经济学》[J].经济学(季刊),2013,12(03):1087-1094.]]></content>
  </entry>
  <entry>
    <title><![CDATA[新项目-ArxivHelper]]></title>
    <url>%2F2019%2F05%2F21%2F%E6%96%B0%E9%A1%B9%E7%9B%AE-ArxivHelper%2F</url>
    <content type="text"><![CDATA[新写成的Arxiv论文阅读与管理应用，带有云端的用户推荐系统，项目地址https://github.com/PKUCSS/arxiv-helper 。 以下为简介。How to run运行方式：java -jar arxiv-helper.jar Authors作者Sishuo Chen,Chonghao Zhai,Zihan,undergraduate students from Peking University,China chensishuo@pku.edu.cn Introduction简介arXiv.org is an electronic preprinted documentary library funded by the National Science Foundation and the US Department of Energy at the Los Alamos (Los Alamos) National Laboratory. It was founded in August 1991 by Dr. 2001. After the year, it was transferred to Cornell University (Cornell University) for maintenance and management. arXiv is the earliest preprint library. There are currently 17 mirror sites around the world. arXiv.ORG involves mathematics, physics, computers, nonlinear science, Quantitative biology, quantitative finance, and several major categories of statistics. Its most important feature is “open access”, which everyone can get for free. Because of the lack of space, arXiv.org’s articles contain more information. Preprints have long replaced traditional research journals in certain areas of physics. arXiv.org是由美国国家科学基金会和美国能源部资助,在美国洛斯阿拉莫斯（Los Alamos）国家实验室建立的电子预印本文献库，始建于1991年8月，由Dr. Ginsparg发起，旨在促进科学研究成果的交流与共享。2001年后转由康奈尔大学（Cornell University）进行维护和管理。arXiv是最早的预印本库，目前世界各地有17个镜像站点。arXiv.org涉及数学，物理、计算机、非线性科学、定量生物学、定量财务以及统计学几大分类。其最重要的特点就是“开放式获取”，每个人都可以免费地获取。由于不受篇幅限制，arXiv.org的文章含有更多信息，预印本在物理学的某些领域，它们早已替代传统的研究期刊。 In the process of using arxiv to retrieve and read papers every day, we found that the user experience of arxiv is not very good, lacking personalized functions such as collection, recommendation, download management, etc., and PDF files can only be downloaded through the browser if they are not downloaded. Reading, when the file name is downloaded, the ID number is unknown, and the experience is poor. Therefore, we completed a Java course project called Arxiv Helper, hoping to help researchers better search and read academic resources and promote the exchange and dissemination of knowledge. 在日常使用arxiv检索和阅读论文的过程中，我们发现arxiv的用户体验并没有做到很好，缺乏收藏、推荐、下载管理等个性化功能，同时PDF文件不下载的话也只能通过浏览器在线阅读，下载时文件名是不明含义的ID编号，体验较差。因此，我们完成了名为Arxiv Helper 的Java课设项目，希望能帮助科研工作者更好地检索和阅读学术资源，促进知识的交流和传播。 Functions功能Arxiv’s latest articles in various fields, based on title/author/domain/summary/full-text search function, online reading and download management, user system based on LeanCloud platform, can realize remote login, access to favorites, reading records, etc. Information, a recommendation system based on text similarity calculations. Arxiv各领域的最新文章获取，基于标题/作者/领域/摘要/全文的搜索功能，论文在线阅读及下载管理，基于LeanCloud平台的用户系统，可以实现异地登录，访问收藏夹、阅读记录等个性化信息，基于文本相似度计算的推荐系统。 Structure架构This project uses maven build, Eclipseb encoding, version management using git, project address is https://github.com PKUCSS/arxiv-helper. We specify external dependencies in the pom file, using the crawler package Jsoup, the user system management platform LeanCloud, and the graphical interface package JavaFX third-party tools. The class that implements the project function is in the src/main/java folder, which has User (user), paper (paper), Promoter (recommended system), UIEngine (graphical interface), PDFViewer (pdf reader), Main (main program). Wait 本项目使用maven构建，Eclipseb编码，使用git做版本管理，项目地址为https://github.com PKUCSS/arxiv-helper。我们在pom文件中指定外部依赖，使用了爬虫包Jsoup、用户系统管理平台LeanCloud、图形界面包JavaFX第三方工具。实现项目功能的类在src/main/java文件夹中，有User(用户)、paper(论文)、Recommender(推荐系统)、UIEngine(图形界面)、PDFViewer(pdf阅读器)、Main(主程序)等 Data数据This project uses Jsoup to obtain paper data from the official Arxiv API. The paper class contains updated (update time), published (release time), authors (author), summary (summary), pdflink (PDF link), categories (domain) and other information. . The search function is implemented in the search class. There are search prefixes (by title/by author/by summary), sort keywords (correlation, release time), and positive sequence reverse order. After building the url, use Jsoup to get the source code of the webpage. Parse out the paper information and return to the paper list. 本项目使用Jsoup从Arxiv官方API获取论文数据，paper类包含updated(更新时间)、published(发布时间)、authors(作者)、summary(摘要)、pdflink(PDF链接)、categories(所属领域)等信息。搜索功能在search类中实现，有搜索前缀(按标题/按作者/按摘要)、排序关键字(相关度、发布时间)、正序逆序等参数，构建出url后用Jsoup获取网页源代码，解析出paper的信息并返回paper列表。 UIDesign图形界面Graphical interface part: This project uses the javafx programming language to develop a graphical interface and uses SceneBuilder to assist in design. Although the time hastily, there is not much energy spent on the art, but this graphical interface strives to cooperate with all the achievable functions of the background data acquisition and user management system, basically the functions are comprehensive, the interface is simple, the paper is readable, and the structure is complete. Better to meet the characteristics of the paper search needs and other characteristics. In addition, this interface also gives tips for use in places where necessary, making it easier for users to get started and solving many problems with current paper search software. 图形界面部分：本项目使用javafx编程语言开发图形界面，并用SceneBuilder辅助设计。虽因时间仓促，在美工上没有花费太多精力，但本图形界面力求配合后台数据获取与用户管理系统所有可实现功能，基本做到功能全面、界面简洁、论文可读性强、结构完整、较好满足论文搜索需求等多个特性。除此之外，本界面还在必要的地方给出了使用提示，使用户更易上手操作，解决了很多目前论文搜索软件的问题。 PDFViewer阅读器In order to solve the problem that JavaFX’s WebEngine component can’t load pdf files, a simple pdf reader is built using Swing graphical interface and AWT component to realize the online opening of PDF and opening local pdf function of given URL through PDFViewer class. A variety of different responses are made based on user actions, which basically meets all possible needs of the user. And the simple interface brought by the characteristics of the Swing component also reduces the difficulty of the user. The function of setting the reading interface is to satisfy the different preferences of the user when reading the thesis in the easiest way. In order to deal with the problem of slow loading, we also added a caching module to load the number of pages to be read in advance to get a more enjoyable reading experience. 为了解决JavaFX的WebEngine组件不能加载pdf文件的问题，使用Swing图形界面和AWT组件搭建了一个简易的pdf阅读器来通过PDFViewer类实现了在线打开给定URL对应的PDF和打开本地pdf功能，并可以根据用户动作做出多种不同响应，基本可以满足用户的所有可能的需求。且Swing组件本身特性带来的简洁界面也降低了用户的使用难度，可以设置阅读界面的功能更是以最简便的方式满足了用户读论文时的不同自身偏好。为了应对加载缓慢的问题，我们还增加了缓存模块，提前加载好将要阅读的页数，获得更畅快的阅读体验。 User System用户系统The user system is built based on the LeanCloud platform, and functions such as user registration, mailbox verification, and password recovery are implemented. The user’s password and reading records, collection papers and other personalized information are encrypted and stored in the cloud, which has strong security and practicality. 基于LeanCloud平台搭建了用户系统，实现了用户注册、邮箱验证、找回密码等功能。用户的密码和阅读记录、收藏论文等个性化信息都经过加密存储在云端，具有很强的安全性和实用性。 Recommending Strategy 推荐策略The text similarity calculation is based on the Jaro-Winkler Distance, and the 25 most similar recommendations to the most recently read papers are selected from the latest papers in the user’s field of interest. 基于Jaro-Winkler Distance进行文本相似度计算，从用户关注领域的最新论文中选取与最近阅读论文最相似的25篇推荐给用户。 Future Works未来的工作Improve PDF readers, improve recommendation strategies, beautify graphical interfaces, and extend to other data sources (BioArxiv, HowNet, etc.) and operating platforms (WeChat, Android, etc.). 改进PDF阅读器、改进推荐策略、美化图形界面、拓展到其他数据来源（(BioArxiv、知网等)和操作平台(微信、安卓等)等。 Summary and Thanks总结与致谢We must first thank the teachers of Huang Jun and Liu Tian and Shen Cheng for their teaching. Their meticulous guidance has enabled us to make progress in Java programming. The skills learned in the Java class will be of great help to the completion of this project. In addition, we would like to thank our friend Xu Dejia for his valuable suggestions for the creativity of the project and the use of the LeanCloud platform. Thanks to the development of Jsoup, JavaFX, and LeanCloud, the tools they developed provide great convenience for our projects. 我们首先要感谢Huang Jun老师和Liu Tian 、Shen Cheng两位助教的教学工作，他们细致耐心的指导使我们在Java编程方面取得了进步，课堂上学到的技能对完成本项目有着巨大的帮助。另外，我们要特别感谢Xu DeJia同学为本项目的创意和LeanCloud平台的使用提供了宝贵的建议。感谢Jsoup、JavaFX、LeanCloud的开发，他们开发的工具为我们的项目提供了极大的便利。 As a docking application for Arxiv’s scientific papers, our original intention is to make “brick workers” easier to access and organize materials, and to promote the exchange and dissemination of knowledge, so we have experience in recommending systems and graphical interfaces. Efforts have been made to make great optimizations. Of course, we hope that this project will not only be handed over as a homework. In the future, we hope to continue to optimize it, expand the functions of the user system, and extend the data source to BioXiv, HowNet and other platforms to accumulate data optimization recommendations. Continue to improve the experience of the graphical interface, and try the development of Android, IOS, WeChat applet and other platforms, to facilitate the daily access to information and knowledge exchanges for college students and researchers. 作为一个对接Arxiv的科技论文阅读应用，我们的初衷就是想让“砖工”们在查阅和整理资料时轻松一些，同时促进知识的交流和传播，因此我们在推荐系统和图形界面的体验方面都努力做出了很大优化。当然，我们希望本项目不仅仅是作为一个作业上交，在未来我们希望能将它继续优化，扩展用户系统的功能，并将数据来源扩展到BioXiv、知网等平台，积累数据优化推荐策略，继续改进图形界面的体验,并尝试安卓、IOS、微信小程序等平台的开发，方便高校学生和科研人员日常查阅资料和知识交流。]]></content>
  </entry>
  <entry>
    <title><![CDATA[网络流（1）]]></title>
    <url>%2F2019%2F04%2F17%2F%E7%BD%91%E7%BB%9C%E6%B5%81%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[网络流(1)基本概念和性质最小割设容量网络$N = ,A \subset V 且 s ∈ A,t ∈ V-A ,称(A,V-A) = \{ | ∈ E 且 i ∈ A , j ∈ V-A \}$为N的割集,$c(A,V-A) = \sum_{ ∈ (A,\bar{A}) } c(i,j)$ 为割集$c(A,V-A)​$的容量，容量最小的割集称为最小割集。 引理1设容量网络$N = $,f为N上的任一可行流，$A \subset V 且 s ∈ A , t ∈ V-A,则 v(f) = \sum_{ ∈ (A,\bar{A})} f(i,j) - \sum_{ ∈ (A,\bar{A})} f(j,i)$ 引理2设f是任一可行流，(A,V-A)是任一割集，则$v(f) \leq c(A,V-A)$ 引理3设f是一个可行流，(A,V-A)是一个割集。如果$v(f) = c(A,V-A)$,则f是最大流，(A,V-A)为最小割集 增广链设容量网络$N = $,f为N上的一个可行流 N中流量等于容量的边称为饱和边，否则称为非饱和边 流量等于0的边称为零流边，否则为非零流边 不考虑边的方向，N中从顶点i到顶点j的一条边不重复的路径称做i-j链，链的方向为从i到j。链中与链的方向一致的边称作前向边，否则称为后向边。 如果链中所有前向边都是非饱和的，所有后向边都是非零流的，则称这条链为i-j增广链 最大流的性质定理1可行流f为最大流 等价于 不存在关于f的s-t增广链 证明： 定理2(最大流最小割集定理)容量网络的最大流的流量等于最小割集的容量。 Fold-Fulkeson算法思想从给定初始可行流(通常取零流开始)，取当前可行流的s-t增广链P,修改P上流量得到新的可行流，重复进行，直到不存在s-t增广链为止 形象的理解 伪代码顶点j得到标号表示已经找到从s到j的增广链，标号为$(l_j,\delta_j)$ ,其中$\delta_j$等于直到j为止链上所有前向边的容量和流量之差以及所有后向边的流量的最小值，$l_j = +i $或$l_j = -i$,前者表示链是从i到j且$$是前向边，后者表示链是从i到j且$$是后向边。 时间复杂度假设所有容量都是正整数，则算法时间复杂度为$O(mC)$,m为边数，$C = \sum_{∈ E}c(s,j)​$ 。(每次流量至少加1，至多C个阶段)，而每阶段标号和修改增广链流量都需要O(m) 改进方法 每次求最短的s-t增广链，即用bfs代替dfs找增广链，Edmonds-Karp算法，$O(nm^2)$ 以POJ1273题为例，链接http://poj.org/problem?id=1273 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;cstring&gt;#include&lt;cmath&gt;using namespace std;int N,M ;int G[300][300] = &#123;&#125; ;int Prev[300] = &#123;&#125; ;bool vis[300] = &#123;&#125; ;unsigned Augument()&#123; int v ; queue&lt;int&gt; q ; memset(Prev,0,sizeof(Prev)) ; memset(vis,0,sizeof(vis)) ; Prev[1] = 0 ; vis[1] = 1 ; q.push(1) ; bool found = 0 ; while ( !q.empty() ) &#123; v = q.front() ; q.pop() ; for (int i = 1 ; i &lt;= M ; ++i ) &#123; if ( G[v][i] &gt; 0 &amp;&amp; vis[i] == 0 ) &#123; Prev[i] = v ; vis[i] = 1 ; if ( i == M ) &#123; found = 1 ; while( !q.empty() ) q.pop() ; break ; &#125; else &#123; q.push(i) ; &#125; &#125; &#125; &#125; if ( !found ) return 0 ; int nMinFlow = 1 &lt;&lt; 30 ; v = M ; while( Prev[v] ) &#123; nMinFlow = min(nMinFlow,G[Prev[v]][v]) ; v = Prev[v] ; &#125; v = M ; while( Prev[v] ) &#123; G[Prev[v]][v] -= nMinFlow ; G[v][Prev[v]] += nMinFlow ; v = Prev[v] ; &#125; return nMinFlow ;&#125;int main () &#123; while( cin &gt;&gt; N &gt;&gt; M ) &#123; int s,e,c ; memset(G,0,sizeof(G)) ; for ( int i = 0 ; i &lt; N ; ++i ) &#123; cin &gt;&gt; s &gt;&gt; e &gt;&gt; c ; G[s][e] += c ; &#125; unsigned ans = 0 ,aug = 0 ; while( aug = Augument() ) &#123; ans += aug ; &#125; cout &lt;&lt; ans &lt;&lt; endl ; &#125; return 0;&#125; 一次标号修改尽可能多条s-t增广链上的流量——Dinic算法 Dinic算法辅助网络（残余网络） 证明正确性的基础——引理4和引理5(详细证明过于繁琐，略去) 引理4 引理5 算法实现 C++代码C++代码（残余网络版，模板题链接http://bailian.openjudge.cn/practice/1469/） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#include &lt;iostream&gt;#include &lt;queue&gt;#include&lt;bits/stdc++.h&gt;using namespace std;int G[1000][1000];int Prev[1000]; //路径上每个节点的前驱节点bool Visited[1000];int Layer[1000]; //Layer[i]是节点i的层号 int n,m,p; //m是顶点数目，顶点编号从1开始 1是源，m是汇, n是边数bool CountLayer() &#123; //分层 int layer = 0; deque&lt;int&gt;q; memset(Layer,0xff,sizeof(Layer)); //都初始化成-1 Layer[1] = 0; q.push_back(1); while( ! q.empty()) &#123; int v = q.front(); q.pop_front(); for( int j = 1; j &lt;= m; j ++ ) &#123; if( G[v][j] &gt; 0 &amp;&amp; Layer[j] == -1 ) &#123; //Layer[j] == -1 说明j还没有访问过 Layer[j] = Layer[v] + 1; if( j == m ) return true; //分层到汇点即可 else q.push_back(j); &#125; &#125; &#125; return false;&#125;int Dinic() &#123; int i; int s; int nMaxFlow = 0; deque&lt;int&gt; q; //DFS用的栈 while( CountLayer() ) &#123; //只要能分层 q.push_back(1); //源点入栈 memset(Visited,0,sizeof(Visited)); Visited[1] = 1; while( !q.empty()) &#123; int nd = q.back(); if( nd == m ) &#123; // nd是汇点 //在栈中找容量最小边 int nMinC = 1 &lt;&lt; 20; int nMinC_vs; //容量最小边的起点 for( i = 1;i &lt; q.size(); i ++ ) &#123; int vs = q[i-1]; int ve = q[i]; if( G[vs][ve] &gt; 0 ) &#123; if( nMinC &gt; G[vs][ve] ) &#123; nMinC = G[vs][ve]; nMinC_vs = vs; &#125; &#125; &#125; //增广，改图 nMaxFlow += nMinC; for( i = 1;i &lt; q.size(); i ++ ) &#123; int vs = q[i-1]; int ve = q[i]; G[vs][ve] -= nMinC; //修改边容量 G[ve][vs] += nMinC; //添加反向边 &#125; //退栈到 nMinC_vs成为栈顶，以便继续dfs while( !q.empty() &amp;&amp; q.back() != nMinC_vs ) &#123; Visited[q.back()] = 0; q.pop_back(); &#125; &#125; else &#123; //nd不是汇点 for( i = 1;i &lt;= m; i ++ ) &#123; if( G[nd][i] &gt; 0 &amp;&amp; Layer[i] == Layer[nd] + 1 &amp;&amp; ! Visited[i]) &#123; //只往下一层的没有走过的节点走 Visited[i] = 1; q.push_back(i); break; &#125; &#125; if( i &gt; m) //找不到下一个点 q.pop_back(); //回溯 &#125; &#125; &#125; return nMaxFlow;&#125;int main()&#123; int T ; scanf("%d",&amp;T) ; while (T-- ) &#123; //m是顶点数目，顶点编号从1开始 scanf("%d %d",&amp;p,&amp;n) ; int i,j,k; int s,e,c; memset( G,0,sizeof(G)) ; for( i = 1;i &lt;= p;i ++ ) &#123; scanf("%d",&amp;c) ; for ( j = 1 ; j &lt;= c ; ++j ) &#123; scanf("%d",&amp;e) ; G[e+1][i+n+1] = 1 ; &#125; &#125; for(int i = 1 ; i &lt;= n ; ++i ) &#123; G[1][i+1] = 1 ; &#125; for(int i = 1 ; i &lt;= p ; ++i ) &#123; G[i+n+1][p+n+2] = 1 ; &#125; m = p+n+2 ; unsigned int MaxFlow = Dinic(); if(MaxFlow == p ) printf("YES\n") ; else printf("NO\n") ; &#125; return 0;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于jar包]]></title>
    <url>%2F2019%2F04%2F16%2F%E5%85%B3%E4%BA%8Ejar%E5%8C%85%2F</url>
    <content type="text"><![CDATA[生成jar包的命令： jar cvfe xx.jar 主类名（不带.java后缀） *（代表目录下所有文件） 执行jar包的命令： java -jar name.jar]]></content>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[春·北京]]></title>
    <url>%2F2019%2F04%2F14%2F%E6%98%A5%C2%B7%E5%8C%97%E4%BA%AC%2F</url>
    <content type="text"><![CDATA[春日迟迟，卉木萋萋。仓庚喈喈，采蘩祁祁。]]></content>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怀念小菊]]></title>
    <url>%2F2019%2F04%2F09%2F%E6%80%80%E5%BF%B5%E5%B0%8F%E8%8F%8A%2F</url>
    <content type="text"><![CDATA[清明那一天，可爱的小菊永远离开了我们。 愿你在喵星一切安好，我们不会忘记你，在燕南园伴我们两度春秋的小精灵。]]></content>
  </entry>
  <entry>
    <title><![CDATA[制度与技术的双重推进——关于经济增长源泉的思考]]></title>
    <url>%2F2019%2F03%2F29%2F%E5%85%B3%E4%BA%8E%E7%BB%8F%E6%B5%8E%E5%A2%9E%E9%95%BF%E6%BA%90%E6%B3%89%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[摘要本文在索洛模型、内生增长理论和新制度经济学的基础上，提出了技术与制度交替作用的观点，认为技术进步和制度演进相互影响，不能简单地将其一归为外生，何者表现为根本性因素取决于特定历史时期内两者边际效用的对比，二者的互相协调是长期经济增长的关键，而当前世界的经济发展主要动力来源于制度演进。 一、为何是技术和制度？经济发展是人类社会进步的基础，广义上的经济发展除物质财富的增加这一根本的数量要素外，还涉及社会公平、人口素质、生活质量等质量要素，但实际研究中通常以人均产值的增长为指标。当然，经济发展不是一代人的事情，要追根溯源必须着眼于长期。经济学界对增长的源泉不断求索，不外乎考虑技术、制度、要素禀赋、文化等要素。笔者认为是技术与制度共同推动了经济发展，而其他因素并非根本，以下为其论证。 要素禀赋分为资源、气候等外在禀赋和人口、资本等内在禀赋。以地理环境与资源为根本因素的”环境决定论”有其适用时期，在前现代历史中，地理环境确实是极为重要的外生因素，”不同民族的历史遵循不同的道路前进，其原因是民族环境的差异”1，但在近现代的技术条件下，非极端的地理环境不会形成太大阻碍，否则就难以解释土地贫瘠的澳大利亚、新西兰等国经济发展胜于拉美各国的事实。而人口、资本等内在可变的禀赋，在逻辑上更应该被归为经济发展的结果而不是原因，在短期内人口/资本比确实具有一定刚性，但长期中实为经济发展的内生变量，不能被视作本因。至于文化、宗教等因素，东亚经济的崛起已经有力地辩驳了”西方至上”的谬论。 观察二战后的世界经济，朝韩、东西德的发展证明了制度差异能导致同文化、同环境的经济体产生巨大的发展差距。而技术进步对经济发展的作用更无需赘言，增长理论的争论点在于技术和制度何为根本，以下继续探究。 二、制度与技术都不是简单外生的制度的演进显然受限于技术决定的物质边界，技术决定论者认为，制度完全内生于技术变迁决定的物质基础，制度完善是一个消极适应的过程。索洛模型即以技术进步解释经济增长的经典理论，得出了人均收入的持续增长只来自技术进步的结论2。但将技术进步假定为外生的，显然是将现实情况过分简化了，在放松外生技术变革假设的前提下，经济增长和技术进步的因果关系就可能发生逆转。 内生增长理论对技术创新过程提供了更全面的阐述。罗默是内生增长理论的先驱，其核心思想可以用一个两部门模型大致概括3———将知识纳入生产函数，将生产部门划分为实物部门和研发部门，最终经济的增长率取决于研发部门的劳动力占比4。这个模型虽然简单，却说明了社会决策对技术进步的速率起到不可忽视的影响。 20世纪70年代后，经济增长的研究受到经济史研究的推动，最终把制度因素纳入解释经济增长中来。诺斯建立了包括产权理论、国家理论、意识形态理论在内的制度变迁理论，认为”一种提供适当的个人刺激的有效制度”是经济增长的关键。这就突破了新古典经济学的框架，将产权、政府等制度要素作为内生变量纳入了经济增长研究中。诺斯关于世界海运量的实证研究5，以及中国家庭联产承包责任制带来的发展绩效，有力地证明了制度要素的重要性。 综合已有理论和实证，我认为技术进步与制度演进是经济发展过程中对立统一、相互影响的一对矛盾体，不能简单断言何为根本，它们的重要程度是随历史进程交替互换的，取决于两者的边际效用之比。 三、边际效用之比决定主要矛盾传统上认为技术决定了一个经济体所能达到的生产可能性边界，制度决定实际的社会生产能否接近这一边界，而制度变迁理论强调交易成本，认为现实中的制度绝不可能完美到使社会生产接近理论上界，同时制度演进也反作用于技术进步，两条曲线始终处于共同外移而又保持一定距离的状态。我认为，何者为主要矛盾，必须结合经济体发展的具体历史时期研究二者的边际效用，下图为具体解释。 我的观点核心在于，从制度和技术的边际效益之比出发，确定一个经济体的发展阶段和发展状态，从而确定技术和制度何者表现为主要矛盾。制度和技术作为一对矛盾统一体，理想状态是二者改进的边际效用相同（制度决定的实际生产位于图中B区和C区的边界线），两条曲线共同向外移动。当然，只要技术和制度的边际效用差不太多，落在协调的范围内（B/C），经济体就表现为良性的经济增长，否则技术上界难以外移（A/D）,经济表现为停滞落后。在极少数制度或技术极为落后的国家（A/D）和发达国家（C）之外，当前世界的大多数国家属于B区，制度形态距离技术要求尚有差距，制度改革表现为经济发展的主要动力。因此，结论是：技术与制度共同推进长期经济发展，何者表现为主要矛盾取决于特定历史时期的边际效用之比。在新一轮科技革命尚未来临、大多数国家为发展中国家的今天，世界经济的长期增长主要来源于制度因素的改进。 参考文献[1] 《枪炮、钢铁与细菌———人类社会的命运》，贾雷德·戴蒙德，1997 [2] Robert Solow,”A Contribution to the Theory of Economics Growth”,Quarterly Journal of Economics(February,1956):65-94 [3] Paul M.Romer,”Increasing Returns and Long-Run Growth”,Journal of Political Economy(October 1986):1002-1037 [4] 参考格里高利·曼昆《宏观经济学》第九版，2016年，201-202页 [5] 诺斯发现，1600-1850年间，世界海洋运输没有发生技术进步，但船运制度和组织方式发生了变化，导致运输成本降低，提高了海洋运输生产率]]></content>
      <tags>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划——副本放置问题]]></title>
    <url>%2F2019%2F03%2F15%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E2%80%94%E2%80%94%E5%89%AF%E6%9C%AC%E6%94%BE%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[动态规划——副本存储问题问题描述在一组服务器$ S=\{𝑠_1,𝑠_2, …,𝑠_𝑛 \} $上放置文件副本, 如果副本放置在$s_i$上, 则产生$c_i$（正的整数值）的存储代价. 当在$s_i $上发生对该文件的访问时, 如果文件副本在$s_i $上, 则无访问代价; 如果不在$s_i$上, 则需要顺序查找$𝑠_{i+1},𝑠{i+2} ,…,s_𝑗$，直到在$s_j$上找到文件副本, 这将产生𝑗−𝑖的访问代价. 规定副本至少一定要放置在$s_n$上, 以便所有的访问均能成功. 问当每个服务器上均发生对该文件的一次访问时, 存储代价加访问代价之和最少是多少? 设计一个算法计算之, 说明算法的正确性, 并分析算法的时间复杂度. 递推方程设F[k]表示只考虑第k+1,k+2,…,n台服务器时最小的总代价，问题目标就是求F[0]。 F[n] = 0\\F[k] = min\{F[j] + c_j + \frac{（j-k)(j-k+1)}{2} | k < j \leq n \} , when:0 \leq nj的含义即第k+1,k+2，…,n中，第一个文件副本的存储位置在哪，通过枚举确定F[k].总的时间复杂度显然为O(n).]]></content>
  </entry>
  <entry>
    <title><![CDATA[贪心算法的正确性证明]]></title>
    <url>%2F2019%2F03%2F15%2F%E8%B4%AA%E5%BF%83%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[贪心算法的正确性证明摘要贪心算法最难的部分就是正确性的证明，常用的方法有归纳法(对算法步数归纳、对问题归纳)和交换论证法（从最优解出发，不变坏地替换，得到贪心策略的解）。下面以三个例子说明这些正确性证法。 活动选择问题——对算法步数归纳 最优装载问题——对问题规模归纳 最小延迟调度——交换论证 活动选择问题问题$S = \{ 1,2,…,n\}$为n项活动的集合，$s_i和f_i$分别为活动i的开始和结束时间，活动i与j相容当且仅当$s_i \geq f_j或s_j&gt;=f_i$,求最大的活动集 贪心策略按截止时间排序 伪代码： 正确性证明：对算法步数归纳定理：算法Select执行到第k步，选择k项活动$i_1=1,i_2,…,i_k$,那么存在最优解A包含$ i_1=1 ,i_2,…,i_k $ 只要此定理成立，算法至多到第n步得到最优解 归纳基础：设$S = \{1,2,….n\}$ 是活动集，活动按截止时间递增顺序排序，k=1，证明存在最优解包含活动1 任取最优解A，A中的活动按照截止时间递增的顺序排列，如果A的第一个活动为j，j不为1，令 A' = (A-\{j\}) ∪\{1\}由于$f_1 &lt;= f_j ，A’$ 也是最优解，而且含有1 归纳步骤： 假设命题对k为真，证明对k+1也为真 算法执行到第k步，选择了活动$i_1=1,i_2,…，i_k$ 根据归纳假设存在最优解A包含$i_1=1,i_2,…,i_k$ ,设最优解A包含$i_1=1,i_2,…，i_k $ ,A中剩下的活动选自集合$S’= \{ i | i ∈ S , s_i \geq f_k \} $ ,且$A = \{i_1,i_2,…，i_ k\} \cup B$ ,B一定是$S’$ 的最优解 根据归纳基础，存在$S’ $ 的最优解B含有$S’$ 中的第一个活动，设为$i_{k+1}$ ,且$|B’| = |B| $,于是 最优装载问题n个集装箱1,2…,n装上轮船，集装箱i的重量为$w_i$ ,轮船载重量限制为$c$ ,无体积限制。如何使装上船的集装箱最多。(假设每个集装箱重量小于c) 贪心策略将集装箱按照从轻到重排序，轻者先装 正确性证明：对规模归纳 设箱子标号按照从轻到重记为1,2,…,n n = 1 贪心选择显然得到最优解 假设对规模n-1的输入得到最优解，证明对规模n的输入也得到最优解 最小延迟调度问题任务集合S，$\forall i∈S $ ,$d_i为截止时间,t_i为加工时间，均为正整数$ 一个调度f:S→N,f(i)为任务i的开始时间。求最大延迟达到最小的调度，即求f 使得 贪心策略按照截止时间$d_i$从小到大选择任务，安排时不留空闲时间 伪代码： 正确性证明：交换论证上述算法的解的性质：没有空闲时间,没有逆序(不存在$f(i) d_j$) 命题1：所有没有逆序、没有空闲时间的调度具有相同的最大延迟 命题1证明：$f_1和f_2$都没有逆序,具有相同截止时间的任务必须被连续安排。在这些连续安排的任务中最大延迟是最后一个任务，被延迟的时间只与已安排任务加工时间之和有关，与任务标号无关。 证明思想：从一个没有空闲时间的最优解出发，在不改变最优性的条件下，转变为没有逆序的解。 如果一个最优调度存在逆序，那么存在i &lt; n使得(i,i+1构成一个逆序) 存在逆序(i,j),j = i + 1,那么交换i和j得到的解的逆序数减一，后面证明这个新的调度仍然最优 至多经过n(n-1)/2次交换得到一个没有逆序的最优调度 交换相邻逆序任务(i,j)不影响最优性： 交换i,j显然对其他任务的延迟时间没有影响 交换后不增加j的延迟 任务i在$f_2$的延迟$L_{2i}$ 小于任务j在$f_1 $ 的延迟$L_{1j}$ 因此小于$ f_1 $的最大延迟]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flower Shots]]></title>
    <url>%2F2019%2F03%2F07%2FFlower-Shots%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>燕园</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python字典扁平化]]></title>
    <url>%2F2019%2F03%2F02%2FPython%E5%AD%97%E5%85%B8%E6%89%81%E5%B9%B3%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一道略有意思的python入门作业题，记之。 题目例如： 输入：src = {‘a’:{‘b’:1,’c’:2},’d’:{‘e’:3,’f’:{‘g’:4}}} 输出：dest = {‘a.b’:1,’a.c’:2,’d.e’:3,’d.f.g’:4} 题解涉及递归：1234567891011ans = &#123;&#125;def flatten(src,pre_key): for key in src: if type(src[key]) == dict: flatten(src[key],pre_key + key) else: ans[pre_key+key] = src[key] return flatten(&#123;'a':&#123;'b':1,'c':2&#125;,'d':&#123;'e':3,'f':&#123;'g':4&#125;&#125;&#125;,"")print(ans)]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DivedeandConquer-1]]></title>
    <url>%2F2019%2F02%2F27%2FDivedeandConquer-1%2F</url>
    <content type="text"><![CDATA[Divide and Conquer求斐波那契数转化为矩阵乘法，用分治法计算，复杂度为$O(logn)$ 位乘问题设X，Y为两个n位二进制数，$n = 2^k$,求XY 传统算法$W(n) = O(n^2)$ 分治法把两个数都对半截，分解为4个子问题 X = A^{n/2}+B , Y = C^{n/2}+D\\ XY = AC2^n + (AD+BC)2^{n-2}+BD\\ W(n) = 4W(n/2) + cn \\ 由主定理 W(n) = O(n^{log4})= O(n^2)，没有本质变化，继续改进： 原本有四个子问题，AC，AD，BC，BD，通过代数变换可以减少为3个 \\ AD+BC = (A-B)（D-C)+AC+BD\\ 则W(n) =3W(n/2)+cn\\ W(n) = O(n^{log3})= O(n^{1.59})矩阵乘法A,B为两个n阶矩阵，计算C = AB 暴力算法不表，$O(n^3)$ 分治法 分解为8个子问题，仍然是$O(n^3)$ 分治法改进：Strassen算法（1969）通过简单的线性变换，将八个子问题变为七个子问题，时间复杂度： W(n) = 7W(n/2)+18(n/2)^2\\ 由主定理 W(n) = O(n^{log_2^7})= O(n^{2.8075})线性变换如下： 现代进展 Coppersmith–Winograd 算法把 N* N大小的矩阵乘法的时间复杂度降低到了：})，而2010年，Andrew Stothers再度把复杂度降低到了})，一年后的2011年，Virginia Williams把复杂度最终定格为：}) 但这些算法常数太大，实际应用较少。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[芯片测试]]></title>
    <url>%2F2019%2F02%2F27%2F%E8%8A%AF%E7%89%87%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[芯片测试问题描述Diogenes教授有n个被认为是完全相同的VLSI芯片，原则上它们是可以互相测试的 教授的测试装置一次可测二片，当该装置中放有两片芯片时，每一片就对另一片作测试并报告其好坏。一个好的芯片总是能够报告另一片的好坏，但一个坏的芯片的结果是不可靠的。这样，每次测试的四种可能结果如下： A报告 B报告 结论 B是好的 A是好的 AB都好或者AB都坏 B是好的 A是坏的 至少一片是坏的 B是坏的 A是好的 至少一片是坏的 B是坏的 A是坏的 至少一片是坏的 暴力方法取一块芯片，一一与其他所有芯片互相检测，假如至少有一半次数报告都是好的，则该芯片是好的。时间复杂度为$O(n^2)$ 分治法伪代码 k ← n while k &gt; 3 do ​ 将芯片分为k/2(下取整)组 ​ 对每一组 ​ if 两片好，任取一片留下 ​ else 两片同时丢掉 ​ k ← 剩下的芯片数 if k == 3 then 任取2片测试 ​ if 至少1坏，取没测的芯片 ​ else 任取1片被测芯片 if k = 2 or 1 then 任取1片 说明上述算法只是一个概要说明，对于 n为奇数的情况需要进一步处理 , 处理时间为 O(n).(剩下的那片用挑出的芯片检测) 复杂度$T(n) = T(n/2)+O(n),W(1)=0$ 由主定理，$W(n) = O(n)$]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扔玻璃杯的学问]]></title>
    <url>%2F2019%2F02%2F25%2F%E6%89%94%E7%8E%BB%E7%92%83%E6%9D%AF%E7%9A%84%E5%AD%A6%E9%97%AE%2F</url>
    <content type="text"><![CDATA[扔玻璃杯的学问问题简述在算分研讨班上第一节课听到的有趣问题，据说是鹅厂面试题： 有一种玻璃杯质量确定但未知，需要检测。有一栋100层的大楼，该种玻璃杯从某一层楼扔下，刚好会碎。现给你两个杯子，问怎样检测出这个杯子的质量，即找到在哪一层楼刚好会碎？ 思路暴力：​ 拿一个杯子从第一层开始往上一直扔，一定能找到答案。最坏需要99次。 ​ 似乎暴力得过头了，而且只用到一个杯子。 改进：​ 分区间扔，充分利用两个杯子。先从第10楼扔，再从第20楼扔，依次下去，如果到某一层碎掉，比如50层碎掉了，我再从41楼开始扔。这样最坏只需要19次。 目前能找到的最佳算法：继续思考刚才方法的缺陷： 当杯子质量比较差的时候，此方法还是比较快速的找到的。比如杯子是在19楼刚好碎，我只需要扔11次，比99楼刚好碎的情况要少很多次。 所以我们的愿望是：杯子的质量无论分布在哪个查找区间，都可以快速地找到。所以我想到的是可以“匀”一下刚才的方法。即 最开始我需要大胆地扔，然后再慢慢小心地扔。 具体方法设计：每次扔的区间减少一层，这样做可以保证每个区间查找的最差次数是一样的。假定第一步在15楼扔，没碎的话则下一步在29楼扔，没碎下一步在42楼扔….碎掉之后则在上一次没碎的楼层开始向上扔。那么最开始在哪一层开始扔呢？？这里我们需要拿支笔算一下：x+(x-1)+(x-2)+…+2 &gt;=100求解出答案为14。 即最终给出的解决方案是：最开始从14楼开始扔，没碎的话在27楼扔，再没碎的话在39楼扔…..一旦碎掉，则从上一次没碎的楼层逐层往上扔，即可快速确认杯子在哪一层刚好会碎掉。 这样的方法可以保证在最差的情况下也能在14次内找到楼层，平均需要的次数不到10次。 技亦灵怪矣哉，算法的trick令人惊叹。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>算法 面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未名湖的水动了]]></title>
    <url>%2F2019%2F02%2F20%2F%E6%9C%AA%E5%90%8D%E6%B9%96%E7%9A%84%E6%B0%B4%E5%8A%A8%E4%BA%86%2F</url>
    <content type="text"><![CDATA[未名湖的水动了​ 湖冰初融，春寒料峭。 ​ 新学期第一次打卡未名湖，忍不住随手拍下几张不成画面的照片。不几日又是元宵，亮灯的博雅塔给人以温暖的归属感。不敢奢望充满挑战的新岁一切顺利，唯愿能长风破浪，勇往直前。 mark一下不多见的亮灯~ 愿新岁安好~]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>日常</tag>
        <tag>美景</tag>
        <tag>燕园</tag>
        <tag>未名湖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hello]]></title>
    <url>%2F2019%2F02%2F17%2Fhello%2F</url>
    <content type="text"><![CDATA[Hello World]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
